{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"cv_rnn_test_1.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"8tI90ej4PRj1","executionInfo":{"status":"ok","timestamp":1605500304898,"user_tz":-480,"elapsed":978,"user":{"displayName":"Mario Plumber","photoUrl":"","userId":"15447310660380136818"}},"outputId":"7be28d53-8d7f-4159-93f2-48e907badc5d","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","os.chdir('/content/drive/My Drive/Colab Notebooks/Projects/TextMining/Text_Classifier1/DeepLearningTrain')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6raVZ5KsPMdd","executionInfo":{"status":"ok","timestamp":1605500306196,"user_tz":-480,"elapsed":829,"user":{"displayName":"Mario Plumber","photoUrl":"","userId":"15447310660380136818"}}},"source":["import pickle\n","import sqlite3\n","import numpy as np\n","import pandas as pd"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"zXuXRbWOPMdu","executionInfo":{"status":"ok","timestamp":1605500307424,"user_tz":-480,"elapsed":791,"user":{"displayName":"Mario Plumber","photoUrl":"","userId":"15447310660380136818"}}},"source":["def split_spaces(data): ## 输入未处理的数据，第二列为文本，返回分割好第二列的列表。\n","    data_list = []\n","    for line in data:\n","        data_list.append(list(line))\n","        \n","    for item in data_list:\n","        item[1] = ' '.join(list(item[1]))\n","    return data_list\n","\n","def desymbol(data):\n","    import re\n","    data_desymbol = []\n","    for line in data:\n","        data_desymbol.append(list(line))\n","    for row in data_desymbol:\n","        row[1] = ' '.join(list(re.sub(\"[\\s+\\.\\!\\/_,$%^*)(+\\\"\\']+|[+——！，。？：、~@#￥%……&*（）“”]\", \"\",row[1])))\n","    return data_desymbol\n","\n","def add_start_end(data):\n","    data_with_se = []\n","    for line in data:\n","        data_with_se.append(list(line))\n","    for row in data_with_se:\n","        row[1] = \"<start> \"+row[1]+\" <end>\"\n","    return data_with_se\n","\n","def countV(x_test):\n","    xtest_cv = cv.transform(x_test)\n","    return xtest_cv\n","\n","def tfIdfV(x_test):\n","    x_test_tfidf = tv.transform(x_test)\n","    \n","    return x_test_tfidf"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"OJYzI7r5PMd1","executionInfo":{"status":"ok","timestamp":1605500309471,"user_tz":-480,"elapsed":820,"user":{"displayName":"Mario Plumber","photoUrl":"","userId":"15447310660380136818"}}},"source":["def load_from_db(num,start):\n","    conn = sqlite3.connect(\"../data/database/texts.db\")\n","    print ('Opened database successfully')\n","    c = conn.cursor()\n","\n","    ci_data=[]\n","    cursor = c.execute(\"SELECT * from ci order by id desc limit \"+str(start)+\",\"+str(num))\n","    for row in cursor:\n","        ci_data.append(row)\n","\n","    poet_data = []\n","    cursor=c.execute(\"SELECT * FROM poet order by id desc limit \"+str(start)+\",\"+str(num))\n","    for row in cursor:\n","        poet_data.append(row)\n","\n","    classical_data = []\n","    cursor=c.execute(\"SELECT * FROM classical order by id desc limit \"+str(start)+\",\"+str(num))\n","    for row in cursor:\n","        classical_data.append(row)\n","\n","    journal_data = []\n","    cursor=c.execute(\"SELECT * FROM journal order by id desc limit \"+str(start)+\",\"+str(num))\n","    for row in cursor:\n","        journal_data.append(row)\n","    \n","    news_data = []\n","    cursor=c.execute(\"SELECT * FROM news order by id asc limit \"+str(start)+\",\"+str(num))\n","    for row in cursor:\n","        news_data.append(row)\n","\n","    print(\"所有类型数据读取成功，数量\"+str(num))\n","    data = ci_data + poet_data + classical_data + journal_data + news_data\n","    \n","    return add_start_end(desymbol(split_spaces(data)))\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"2NAmDbQvPMd8","executionInfo":{"status":"ok","timestamp":1605500315207,"user_tz":-480,"elapsed":4434,"user":{"displayName":"Mario Plumber","photoUrl":"","userId":"15447310660380136818"}},"outputId":"becc0cfb-0c03-4722-8b6d-8e3177b585b9","colab":{"base_uri":"https://localhost:8080/"}},"source":["file = open(\"../model/CV.pkl\", \"rb\")\n","cv = pickle.load(file)\n","file.close()\n","\n","file = open(\"../model/TV.pkl\", \"rb\")\n","tv = pickle.load(file)\n","file.close()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.23.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.23.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.23.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n","  UserWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Cr6LKLcRPMeA","executionInfo":{"status":"ok","timestamp":1605500317090,"user_tz":-480,"elapsed":833,"user":{"displayName":"Mario Plumber","photoUrl":"","userId":"15447310660380136818"}}},"source":["def get_text(data):\n","    textlist = []\n","    if(len(np.array(data).shape) > 1):\n","        for row in data:\n","            textlist.append(row[1])\n","    else: textlist.append(data[1])\n","    return textlist"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"cGeoEQSqPMeE","executionInfo":{"status":"ok","timestamp":1605500334361,"user_tz":-480,"elapsed":16613,"user":{"displayName":"Mario Plumber","photoUrl":"","userId":"15447310660380136818"}},"outputId":"e0f65f9e-7a16-404e-b63b-eef13d47927b","colab":{"base_uri":"https://localhost:8080/"}},"source":["data = load_from_db(2000,0)\n","textlist = get_text(data)\n","# c = {\"text\":textlist,\"cv\":list(countV(textlist)),\"tfIdf\":list(tfIdfV(textlist))}\n","# df = pd.DataFrame(c)\n","\n","# display(df)\n","# print(tfIdfV(textlist).shape)\n","# print(list(tfIdfV(textlist))[5])\n","test_data = load_from_db(200,18000)\n","test_textlist = get_text(data)\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Opened database successfully\n","所有类型数据读取成功，数量2000\n","Opened database successfully\n","所有类型数据读取成功，数量200\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dXOWigXsPMeL","executionInfo":{"status":"ok","timestamp":1605500344535,"user_tz":-480,"elapsed":862,"user":{"displayName":"Mario Plumber","photoUrl":"","userId":"15447310660380136818"}},"outputId":"b725ee40-546e-4f83-ce92-adb86b81381a","colab":{"base_uri":"https://localhost:8080/"}},"source":["y_train = []\n","for row in data:\n","    y_train.append(row[2])\n","print(y_train[0])\n","for i in range(len(y_train)):\n","    if y_train[i] ==\"modern\":\n","        y_train[i]=0\n","    elif y_train[i] ==\"ci\":\n","        y_train[i]=1\n","    elif y_train[i] ==\"poet\":\n","        y_train[i]=1\n","    elif y_train[i] ==\"classical\":\n","        y_train[i]=1\n","print(y_train[0])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["ci\n","1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DeFfphDgPMeg","executionInfo":{"status":"ok","timestamp":1605500347634,"user_tz":-480,"elapsed":1055,"user":{"displayName":"Mario Plumber","photoUrl":"","userId":"15447310660380136818"}},"outputId":"9ca64cb4-6c6f-4d16-d254-107aa93b3db9","colab":{"base_uri":"https://localhost:8080/"}},"source":["y_test = []\n","for row in test_data:\n","    y_test.append(row[2])\n","print(y_test[0])\n","for i in range(len(y_test)):\n","    if y_test[i] ==\"modern\":\n","        y_test[i]=0\n","    elif y_test[i] ==\"ci\":\n","        y_test[i]=1\n","    elif y_test[i] ==\"poet\":\n","        y_test[i]=1\n","    elif y_test[i] ==\"classical\":\n","        y_test[i]=1\n","print(y_test[0])"],"execution_count":10,"outputs":[{"output_type":"stream","text":["ci\n","1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9Jhxr4HdPMe-","executionInfo":{"status":"ok","timestamp":1605500355747,"user_tz":-480,"elapsed":6592,"user":{"displayName":"Mario Plumber","photoUrl":"","userId":"15447310660380136818"}}},"source":["x_train_cv = countV(textlist)\n","x_train_tfidf = tfIdfV(textlist)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"xhkR8oc-PMfH","executionInfo":{"status":"ok","timestamp":1605500362980,"user_tz":-480,"elapsed":3675,"user":{"displayName":"Mario Plumber","photoUrl":"","userId":"15447310660380136818"}}},"source":["x_test_cv = countV(textlist)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"BXLJroekPMfO","executionInfo":{"status":"ok","timestamp":1605501973413,"user_tz":-480,"elapsed":482850,"user":{"displayName":"Mario Plumber","photoUrl":"","userId":"15447310660380136818"}},"outputId":"0bba0cb6-c7a1-44e2-e99f-d0f36fb9ec97","colab":{"base_uri":"https://localhost:8080/"}},"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import numpy as np\n","import sklearn\n","import string\n","import random\n","# nltk.download('names')\n","# from nltk.corpus import names\n","\n","USE_CUDA = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n","\n","'''\n","将名字编码为向量：每个字符为one-hot编码，将多个字符的向量进行堆叠\n","abc = [ [1, 0, ...,0]\n","        [0, 1, 0, ..]\n","        [0, 0, 1, ..] ]\n","abc.shape = (len(\"abc\"), len(chars))\n","'''\n","# def name2vec(name):\n","#     ids = [chars.index(c) for c in name if c not in [\"\\\\\"]]\n","\n","#     a = np.zeros(shape=(len(ids), len(chars)))\n","#     for i, idx in enumerate(ids):\n","#         a[i][idx] = 1\n","#     return a\n","\n","\n","# def load_data():\n","#     female_file, male_file = names.fileids()\n","\n","#     f1_names = names.words(female_file)\n","#     f2_names = names.words(male_file)\n","\n","#     data_set = [(name.lower(), 0) for name in f1_names] + [(name.lower(), 1) for name in f2_names]\n","#     data_set = [(name2vec(name), sexy) for name, sexy in data_set]\n","#     random.shuffle(data_set)\n","#     return data_set\n","\n","\n","class CharRNN(nn.Module):\n","    def __init__(self, vocab_size, hidden_size, output_size):\n","        super(CharRNN, self).__init__()\n","        self.vocab_size = vocab_size\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","\n","        self.rnn = nn.RNN(vocab_size, hidden_size, batch_first=True)\n","        self.liner = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, input):\n","        h0 = torch.zeros(1, 1, self.hidden_size, device=device) # 初始hidden state\n","        output, hidden = self.rnn(input, h0)\n","        output = output[:, -1, :] # 只使用最终时刻的输出作为特征\n","        output = self.liner(output)\n","        output = F.softmax(output, dim=1)\n","        return output\n","\n","hidden_dim = 128\n","output_dim = 2\n","\n","class Model:\n","    def __init__(self, epoches=100):\n","        self.model = CharRNN(20000, hidden_dim , output_dim)\n","        self.model.to(device)\n","        self.epoches = epoches\n","\n","    def train(self,x_train,y_train):\n","        loss_func = nn.CrossEntropyLoss()\n","        optimizer = torch.optim.RMSprop(self.model.parameters(), lr=0.0003)\n","\n","        for epoch in range(self.epoches):\n","            total_loss = 0\n","            for x in range(len(y_train)):# 每轮随机样本训练1000次\n","#                 name, sexy = random.choice(train_set)\n","                texts , typetext = x_train[x],y_train[x]\n","#                 # RNN的input要求shape为[batch, seq_len, embed_dim]，由于名字为变长，也不准备好将其填充为定长，因此batch_size取1，将取的名字放入单个元素的list中。\n","#                 name_tensor = torch.tensor([name], dtype=torch.float, device=device)\n","                texts_tensor = torch.tensor([texts.toarray()], dtype=torch.float,device=device)\n","                typetext_tensor = torch.tensor([typetext], dtype=torch.long, device=device)\n","#                 # torch要求计算损失时，只提供类别的索引值，不需要one-hot表示\n","#                 sexy_tensor = torch.tensor([sexy], dtype=torch.long, device=device)\n","\n","                optimizer.zero_grad()\n","\n","                pred = self.model(texts_tensor) # [batch, out_dim]\n","                loss = loss_func(pred, typetext_tensor)\n","                loss.backward()\n","                total_loss += loss\n","                optimizer.step()\n","            print(\"Training: in epoch {} loss {}\".format(epoch, total_loss/1000))\n","\n","    def evaluate(self,x_test,y_test):\n","        with torch.no_grad(): # 评估时不进行梯度计算\n","            correct = 0\n","            for x in range(len(y_test)): # 从测试集中随机采样测试1000次\n","#                 name, sexy = random.choice(test_set)\n","#                 name_tensor = torch.tensor([name], dtype=torch.float, device=device)\n","                texts , typetext = x_test[x],y_test[x] \n","                texts_tensor = torch.tensor([texts.toarray()], dtype=torch.float,device=device)\n","                \n","                pred = self.model(texts_tensor)\n","                if torch.argmax(pred).item() == typetext:\n","                    correct += 1\n","\n","            print('Evaluating: test accuracy is {}%'.format(correct*100/len(y_test)))\n","\n","#     def predict(self, name):\n","#         p = name2vec(name.lower())\n","#         name_tensor = torch.tensor([p], dtype=torch.float, device=device)\n","#         with torch.no_grad():\n","#             out = self.model(name_tensor)\n","#             out = torch.argmax(out).item()\n","#             sexy = 'female' if out == 0 else 'male'\n","#             print('{} is {}'.format(name, sexy))\n","\n","\n","model = Model(10)\n","#     data_set = load_data()\n","#     train, test = sklearn.model_selection.train_test_split(data_set)\n","model.train(x_train_cv,y_train)\n","model.evaluate(x_test_cv,y_test)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Training: in epoch 0 loss 4.837851524353027\n","Training: in epoch 1 loss 4.4026899337768555\n","Training: in epoch 2 loss 3.203468084335327\n","Training: in epoch 3 loss 3.1627461910247803\n","Training: in epoch 4 loss 3.1523489952087402\n","Training: in epoch 5 loss 3.1426098346710205\n","Training: in epoch 6 loss 3.1383049488067627\n","Training: in epoch 7 loss 3.1390655040740967\n","Training: in epoch 8 loss 3.1388285160064697\n","Training: in epoch 9 loss 3.1343703269958496\n","Evaluating: test accuracy is 6000.0%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GAmhjomXPMfa","outputId":"5b912708-a5e6-4189-f4c9-1caa24055f67"},"source":["print(x_train_cv[0])\n","print(x_train_cv.toarray()[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  (0, 2)\t8\n","  (0, 195)\t1\n","  (0, 256)\t1\n","  (0, 319)\t1\n","  (0, 629)\t1\n","  (0, 632)\t1\n","  (0, 638)\t1\n","  (0, 640)\t1\n","  (0, 644)\t1\n","  (0, 667)\t1\n","  (0, 669)\t1\n","  (0, 676)\t1\n","  (0, 680)\t1\n","  (0, 684)\t1\n","  (0, 685)\t2\n","  (0, 686)\t1\n","  (0, 2647)\t1\n","  (0, 4156)\t1\n","  (0, 5340)\t1\n","  (0, 8267)\t1\n","  (0, 10130)\t1\n","  (0, 12559)\t1\n","  (0, 12781)\t1\n","[0 0 8 ... 0 0 0]\n"],"name":"stdout"}]}]}