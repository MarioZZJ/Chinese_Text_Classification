{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.引入所有需要的库和数据集\n",
    "- 包含word2vec模型、pandas、numpy和gensim\n",
    "- 其中Gensim是一款开源的第三方Python工具包，用于从原始的非结构化的文本中，无监督地学习到文本隐层的主题向量表达。它支持包括TF-IDF，LSA，LDA，和word2vec在内的多种主题模型算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import pandas,  numpy, textblob, string #xgboost,\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "#from keras.preprocessing import text, sequence\n",
    "#from keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened database successfully\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect(\"data/database/texts.db\")\n",
    "\n",
    "print ('Opened database successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add successfully\n"
     ]
    }
   ],
   "source": [
    "c = conn.cursor()\n",
    "\n",
    "ci_data=[]\n",
    "cursor = c.execute(\"SELECT * from ci order by id asc limit 4000\")\n",
    "#cursor = c.execute(\"SELECT * from ci order by id\")\n",
    "for row in cursor:\n",
    "    ci_data.append(row)\n",
    "#print(\"读取的词数据样例：\")\n",
    "#print(ci_data[-2:])\n",
    "\n",
    "poet_data = []\n",
    "cursor=c.execute(\"SELECT * FROM poet order by id asc limit 4000\")\n",
    "#cursor = c.execute(\"SELECT * from poet order by id\")\n",
    "for row in cursor:\n",
    "    poet_data.append(row)\n",
    "#print(\"\\n读取的诗数据样例：\")\n",
    "#print(poet_data[-2:])\n",
    "\n",
    "classical_data = []\n",
    "cursor=c.execute(\"SELECT * FROM classical order by id asc limit 4000\")\n",
    "#cursor = c.execute(\"SELECT * from classical order by id\")\n",
    "for row in cursor:\n",
    "    classical_data.append(row)\n",
    "#print(\"\\n读取的文言文数据样例：\")\n",
    "#print(classical_data[-2:])\n",
    "\n",
    "journal_data = []\n",
    "cursor=c.execute(\"SELECT * FROM journal order by id asc limit 4000\")\n",
    "#cursor = c.execute(\"SELECT * from journal order by id\")\n",
    "for row in cursor:\n",
    "    journal_data.append(row)\n",
    "#print(\"\\n读取的期刊数据样例：\")\n",
    "#print(journal_data[:2])\n",
    "    \n",
    "news_data = []\n",
    "cursor=c.execute(\"SELECT * FROM news order by id asc limit 4000\")\n",
    "#cursor=c.execute(\"SELECT * FROM news\")\n",
    "for row in cursor:\n",
    "    news_data.append(row)\n",
    "#print(\"\\n读取的新闻数据样例：\")\n",
    "#print(news_data[:2])\n",
    "\n",
    "print(\"add successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40002209, '中兴曾作故人看，抗节唯怜七里滩。 枯枿卧沙疑野艇，丛篁生岸忆长竿。 天边旧迹星辰动，江上余基水石寒。 应笑渭滨周吕望，白头因猎从和銮。 ', 'poet', 'd1fcb4d4-c756-418d-927d-b77c92901a98']\n",
      "['中 兴 曾 作 故 人 看 ， 抗 节 唯 怜 七 里 滩 。   枯 枿 卧 沙 疑 野 艇 ， 丛 篁 生 岸 忆 长 竿 。   天 边 旧 迹 星 辰 动 ， 江 上 余 基 水 石 寒 。   应 笑 渭 滨 周 吕 望 ， 白 头 因 猎 从 和 銮 。  ', 'poet']\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "data = ci_data + poet_data + classical_data + journal_data + news_data\n",
    "\n",
    "data_list = []\n",
    "for line in data:\n",
    "    data_list.append(list(line))\n",
    "\n",
    "print(data_list[6000])\n",
    "for item in data_list:\n",
    "    item[1] = ' '.join(list(item[1]))\n",
    "for i in range(len(data_list)):\n",
    "        data_list[i].remove(data_list[i][3])\n",
    "        data_list[i].remove(data_list[i][0])\n",
    "print(data_list[6000])\n",
    "print(len(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['气和玉烛，睿化著鸿明。 缇管一阳生。 郊盛礼燔柴毕，旋轸凤凰城。 森罗仪卫振华缨。 载路溢欢声。 皇图大业超前古，垂象泰阶平。 岁时丰衍，九土乐升平。 睹寰海澄清。 道高尧舜垂衣治，日月并文明。 嘉禾甘露登歌荐，云物焕祥经。 兢兢惕惕持谦德，未许禅云亭。', '严夜警，铜莲漏迟迟。 清禁肃，森陛戟，羽卫俨皇闱。 角声励，钲鼓攸宜。 金管成雅奏，逐吹逶迤。 荐苍璧，郊祀神祗。 属景运纯禧。 京坻丰衍，群材乐育，诸侯述职，盛德服蛮夷。 殊祥萃，九苞丹凤来仪。 膏露降，和气洽，三秀焕灵芝。 鸿猷播，史册相辉。 张四维。 卜世永固丕基。 敷玄化，荡荡无为。 合尧舜文思。 混并寰宇，休牛归马，销金偃革，蹈咏庆昌期。', '承宝运，驯致隆平。 鸿庆被寰瀛。 时清俗阜，治定功成。 遐迩咏由庚。 严郊祀，文物声明。 会天正、星拱奏严更。 布羽仪簪缨。 宸心虔洁，明德播惟馨。 动苍冥。 神降享精诚。 燔柴半，万乘移天仗，肃銮辂旋衡。 千官云拥，群后葵倾。 玉帛旅明庭。 韶荐，金奏谐声。 集休亨。 皇泽浃黎庶，普率洽恩荣。 仰钦元后，睿圣贯三灵。 万邦宁。 景贶福千龄。']\n",
      "['modern', 'modern', 'modern']\n"
     ]
    }
   ],
   "source": [
    "train_data=[]\n",
    "train_target=[]\n",
    "for i in range(0,len(data)):\n",
    "    train_data.append(data[i][1])\n",
    "    train_target.append(data[i][2])\n",
    "print(train_data[:3])\n",
    "print(train_target[15000:15003])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_data, train_target,test_size=0.3,random_state=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 数据预处理与格式转化\n",
    "### （1）构建标签字典\n",
    "> 标签种类总数为36种，共有52w多个标签\n",
    "\n",
    "- *list(set())*的功能是:对原列表去重并按从小到大排序。\n",
    "- labels中存放的是所有的样本，而去重后的labels_type中存放的是词性的所有种类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ci', 'classical', 'poet', 'modern']\n",
      "['classical', 'classical', 'classical', 'modern', 'modern', 'modern', 'modern', 'ci', 'classical', 'modern']\n",
      "20000\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "labels = y_train + y_test\n",
    "labels_types = list(set(labels))\n",
    "\n",
    "print(labels_types[:10])\n",
    "print(labels[:10])\n",
    "print(len(labels))\n",
    "print(len(labels_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 构建字典\n",
    "- update()函数用于将两个字典合并操作，有相同的就覆盖，在此处只是把每个类别和对应出现的次数进行统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the count of total labels is : 20000\n",
      "the number of types of labels is : 4\n"
     ]
    }
   ],
   "source": [
    "labels_dict = {}\n",
    "labels_index = {\"padded_label\" : 0}\n",
    "\n",
    "for index in range(len(labels_types)):\n",
    "    label = labels_types[index]\n",
    "    labels_dict.update({label: labels.count(label)})\n",
    "    labels_index.update({label: index+1})\n",
    "\n",
    "np.save('y_labels_index.npy', labels_index)     \n",
    "print(\"the count of total labels is : \"+ str(len(labels)) + \"\\nthe number of types of labels is : \" + str(len(labels_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 输出字典（键：类别；值：出现次数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the specific types and correspond counts: \n",
      "Items held\n",
      "ci  :4000\n",
      "classical:4000\n",
      "poet:4000\n",
      "modern:8000\n"
     ]
    }
   ],
   "source": [
    "def print_inventory(dct):\n",
    "    print(\"Items held\")\n",
    "    for item, amount in dct.items():\n",
    "        print(\"{:<4}:{}\".format(item, amount))\n",
    "\n",
    "print(\"Here are the specific types and correspond counts: \")\n",
    "print_inventory(labels_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### （2）切分句子\n",
    "- 因为要考虑词与词之间的关系，因此要把文本切分成句子\n",
    "\n",
    "> 在文档中的每个句子之间以空格进行分隔，因此可以根据分辨出的空行来分隔每句话"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 进行数据集的拆分，并给出一些句子的词性标注的demo\n",
    "\n",
    "> 转化成计算机语言，因此要转换成索引（数字表示类别）\n",
    "\n",
    "- 可以看到类别由前面的string值按照排序后的index值转变成了数字表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [1], [1], [3], [3]]\n"
     ]
    }
   ],
   "source": [
    "def transfer_label_category_index(origin_labels, labels_types):\n",
    "    transfered_label = []\n",
    "    for sentence_labels in origin_labels:\n",
    "        labels_format_index = [labels_types.index(sentence_labels)]  # 将标签依据字典转化为序号\n",
    "        transfered_label.append(labels_format_index)\n",
    "    return transfered_label\n",
    "\n",
    "y_train_index = transfer_label_category_index(y_train, labels_types)\n",
    "y_test_index = transfer_label_category_index(y_test, labels_types)\n",
    "\n",
    "print(y_train_index[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### （3）设置定长向量\n",
    "- 循环神经网络中处理的是定长向量的问题，因此要限定句子的长度\n",
    "- 本次实验中设置每句长度为100个词，不满100个词的句子剩余部分全填充为0，因此在此处可以把y标签填充到100个词（不满100的话全部填充为0），保证传入的是一个定长向量因此可以进行矩阵计算\n",
    "---\n",
    "### （4）构建张量\n",
    "- np.zeros()：构建全0的张量\n",
    "> ***三个维度的张量：***\n",
    "1. 标签的样本数（句子数）\n",
    "2. 句子的长度（本例中设定的是100）\n",
    "3. 标签的类别数（36个种类）\n",
    "\n",
    "> 因此在此处转换成的是三维数组，最低维的代表词性的种类，每个元素是一个词，用这个办法可以把所有y_label转成三维数组表示。\n",
    "第二个维度表示一个句子中包含的词，第三个维度代表所有句子\n",
    "\n",
    "> 在此增加了一个标签种类，总的类数增加到37，加的是一个特殊的类，用来表示长度超出100后被略掉的词\n",
    "\n",
    "---\n",
    "- 填充张量：判断对应的词性并把相应的位置由0替换成1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将y_train更改为一维向量，并转换为tensor类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classical\n",
      "<class 'int'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(y_train[0])\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i] ==\"modern\":\n",
    "        y_train[i]=0\n",
    "    elif y_train[i] ==\"ci\":\n",
    "        y_train[i]=1\n",
    "    elif y_train[i] ==\"poet\":\n",
    "        y_train[i]=2\n",
    "    elif y_train[i] ==\"classical\":\n",
    "        y_train[i]=3\n",
    "print(type(y_train[0]))\n",
    "train_y=torch.tensor(y_train)\n",
    "print(type(train_y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modern\n",
      "<class 'int'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0])\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] ==\"modern\":\n",
    "        y_test[i]=0\n",
    "    elif y_test[i] ==\"ci\":\n",
    "        y_test[i]=1\n",
    "    elif y_test[i] ==\"poet\":\n",
    "        y_test[i]=2\n",
    "    elif y_test[i] ==\"classical\":\n",
    "        y_test[i]=3\n",
    "print(type(y_test[0]))\n",
    "test_y=torch.tensor(y_test)\n",
    "print(type(test_y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3、word2vec模型导入\n",
    "### 目的：进入对x的处理\n",
    "\n",
    "> 导入word2vec的原因：word2vec本身具有词典，与语料库的词典进行对应为后续实验做简化\n",
    "\n",
    "- 预训练的word2vec模型采用前人用中文维基百科训练好的模型\n",
    "\n",
    "[word2vec模型链接](https://github.com/Embedding/Chinese-Word-Vectors)\n",
    "\n",
    "- 模型以二进制存储，因此要用特殊的形式读入（load方式）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-46b527d9b3e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## 1 导入 预训练的词向量\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmyPath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'data/sgns.wiki.char.bz2'\u001b[0m \u001b[1;31m# 本地词向量的地址\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mWord2VecModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m \u001b[1;31m# 读取词向量，以二进制读取\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mvector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWord2VecModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'空间'\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# 词语的向量，是numpy格式\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[0;32m   1496\u001b[0m         return _load_word2vec_format(\n\u001b[0;32m   1497\u001b[0m             \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1498\u001b[1;33m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[0;32m   1499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\gensim\\models\\utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mline_no\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m                 \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb''\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"unexpected end of input; is count incorrect or file otherwise damaged?\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\bz2.py\u001b[0m in \u001b[0;36mreadline\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_can_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"B\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\_compression.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                     \u001b[0mrawblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## 1 导入 预训练的词向量\n",
    "myPath = 'data/sgns.wiki.char.bz2' # 本地词向量的地址\n",
    "Word2VecModel = gensim.models.KeyedVectors.load_word2vec_format(myPath).wv # 读取词向量，以二进制读取\n",
    "\n",
    "vector = Word2VecModel.wv['空间']  # 词语的向量，是numpy格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.models.keyedvectors.Word2VecKeyedVectors'>\n",
      "，\n",
      "Vocab(count:352221, index:0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ana\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ana\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "print(type(Word2VecModel.wv)) # 结果为：Word2VecKeyedVectors\n",
    "\n",
    "for i,j in Word2VecModel.wv.vocab.items():\n",
    "    print(i) # 此时 i 代表每个单词\n",
    "    print(j) # j 代表封装了 词频 等信息的 gensim“Vocab”对象，例子：Vocab(count:1481, index:38, sample_int:3701260191)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ana\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "## 2 构造包含所有词语的 list，以及初始化 “词语-序号”字典 和 “词向量”矩阵\n",
    "vocab_list = [word for word, Vocab in Word2VecModel.wv.vocab.items()]# 存储 所有的 词语\n",
    "\n",
    "word_index = {\" \": 0}# 初始化 `[word : token]` ，后期 tokenize 语料库就是用该词典。\n",
    "word_vector = {} # 初始化`[word : vector]`字典\n",
    "\n",
    "# 初始化存储所有向量的大矩阵，留意其中多一位（首行），词向量全为 0，用于 padding补零。\n",
    "# 行数 为 所有单词数+1 比如 10000+1 ； 列数为 词向量“维度”比如100。\n",
    "embeddings_matrix = np.zeros((len(vocab_list) + 1, Word2VecModel.vector_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ana\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n",
      "C:\\ana\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "## 3 填充 上述 的字典 和 大矩阵\n",
    "for i in range(len(vocab_list)):\n",
    "    # print(i)\n",
    "    word = vocab_list[i]  # 每个词语\n",
    "    word_index[word] = i + 1 # 词语：序号\n",
    "    word_vector[word] = Word2VecModel.wv[word] # 词语：词向量\n",
    "    embeddings_matrix[i + 1] = Word2VecModel.wv[word]  # 词向量矩阵\n",
    "    \n",
    "np.save('x_word_index.npy', word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 之后需要对语料库数据进行转换：\n",
    "- 1、文本转化成序号（利用word_index），替换过后的x的表示可以通过序号可以找到对应的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5737     21   2746   1201   1716   1125      1   2031   7813   2311\n",
      "   18043      1     41   1893   4325   1345  13031     64   2763   4839\n",
      "       1  13152     25  47854  19271      3   5549      7     10   1893\n",
      "     119  16660      1   9050   5006     25   4325     64      3    638\n",
      "    1874     25   2225  12191      1   1890   6725     19   1058      1\n",
      "    9265  40160   7430   9976      1     66    211     41   1201   8767\n",
      "     678      1   9467     31   9642     64      3   2311    678   4280\n",
      "   23928   1582   9180      1   7134   1305   1377   2038      3   1760\n",
      "    2688   2292   9180      1  60225  12863   7272   2926      3  53202\n",
      "    6649  68365   6288      1   5255  18043  12384   1878      3     62]\n",
      " [     0      0      0      0  19955   3846     28   4784    707      1\n",
      "    4784    707  21942  18040      1  12072  20461  31005      1   4815\n",
      "     112  29379   6699      1  19955   3846    678   2665    640  12429\n",
      "       3  19955   3846     28   4784    707      1      0   4784    707\n",
      "    6689    548   4638      1    116    601     31     65      3  19955\n",
      "    3846     28   4784    707      1   1480     21   8389    678   5549\n",
      "       7   5314    863      1  10711     21   4313     30      3     16\n",
      "     116   4222      0   3350  17977     31   6427      3      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0      0  89874      1   4842  13833    821   6646      1    270\n",
      "     211   2746      3  10229   1951    137     28    821   8613      1\n",
      "   82331   1639     64   8068      3   1893    116  13833  89874   1131\n",
      "    7696  44044      1    227  89874   1305    928   1867    800   6646\n",
      "      64   5035      1  19271    116     72     41     10  11488     16\n",
      "     579     10  71159     16     64   5111      1    937     64    734\n",
      "    3021     41     10   6646     16     41     10  11488     16      1\n",
      "     125   1078    123   2141      1   6847    368   1847   1199   1639\n",
      "     570      1   1482    215   1878   8772     10  19538     66     91\n",
      "    4638     16      1   1480    368   4088   1639      1    119    211]\n",
      " [    58     94     50      0    619     18    688   8705   6459   2117\n",
      "   11200   1839  19358  25317     31    640   2268    917  13264     54\n",
      "      50      0   3351    218   3351    182      2   1660   4837     21\n",
      "   10180     65   1165    228   6284   3917   4903   4313   1660   7095\n",
      "      50      0  12266   5314    137    764  11964    688      2   2580\n",
      "    2268      3   2350   5773    228     50      0     18    688   1077\n",
      "    2763    947    688    934      2  42611   7359    991    201     11\n",
      "     451    805     41     10   3271    245     16   1498   6596  42611\n",
      "    7359     50      0    579     18    688    137   2763    947    688\n",
      "     934   2580   2268     18    863   8705   6459     50      0    798]\n",
      " [  2998   7307    201   4429   1707  40282   1667   4903    808      1\n",
      "     879     19   4865   1025      1     21     91     27     22   2763\n",
      "    1358  20153   1906      9    950   4700   5672    920   2268   1167\n",
      "    8704    148    201   9195      3     82     29   1196  28329    215\n",
      "       2    148    707     17    218     22   6844     13   1751    218\n",
      "       3     21   6915   5328   9153   5264   4450   1195  15243    764\n",
      "     640     91     27  10210  12119      2  13957   1722   1165      1\n",
      "      40   4956   6844     13     29   1196   1893    215      2    148\n",
      "     707      3  32617  59800      0  36837  14821  10322   3975    769\n",
      "       2   8911   9570    388    928    218  30200 179609      2    950]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "# 序号化 文本，tokenizer句子，并返回每个句子所对应的词语索引\n",
    "MAX_SEQUENCE_LENGTH=100\n",
    "# 由于将词语转化为索引的word_index需要与词向量模型对齐，故在导入词向量模型后再将X进行处理\n",
    "def tokenizer(texts, word_index):\n",
    "    data = []\n",
    "    for sentence in texts:\n",
    "        new_sentence = []\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                new_sentence.append(word_index[word])  # 把文本中的 词语转化为index\n",
    "            except:\n",
    "                new_sentence.append(0)\n",
    "            \n",
    "        data.append(new_sentence)\n",
    "    # 使用kears的内置函数padding对齐句子,好处是输出numpy数组，不用自己转化了\n",
    "    data = sequence.pad_sequences(data, maxlen = MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "    \n",
    "    return data\n",
    "\n",
    "x_train_tokenized = tokenizer(x_train, word_index)\n",
    "x_test_tokenized = tokenizer(x_test, word_index)\n",
    "\n",
    "print(x_train_tokenized[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14000, 100])\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(x_train_tokenized)):\n",
    "    x_train_tokenized[i]=torch.tensor(x_train_tokenized[i])\n",
    "    #print(type(x_train_tokenized[i]))\n",
    "x_train_tokenize=torch.tensor(x_train_tokenized)\n",
    "print(x_train_tokenize.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6000, 100])\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(x_test_tokenized)):\n",
    "    x_test_tokenized[i]=torch.tensor(x_test_tokenized[i])\n",
    "    #print(type(x_train_tokenized[i]))\n",
    "x_test_tokenize=torch.tensor(x_test_tokenized)\n",
    "print(x_test_tokenize.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch import optim\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x = x.unsqueeze(dim=1)\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx],self.y[idx]\n",
    "train_DL = DataLoader(Dataset(x_train_tokenize,train_y.long()),batch_size=1,shuffle=True)\n",
    "test_DL=DataLoader(Dataset(x_test_tokenize,test_y.long()),batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 尝试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, num_hiddens, num_layers):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn=nn.RNN(input_size=embedding_dim,hidden_size=num_hiddens,num_layers=num_layers)\n",
    "        \n",
    "        self.out = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        outputs, _ = self.out(inputs) # output, (h, c)\n",
    "        \n",
    "        outs = self.out(outputs[:, -1, :])\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(100, 64)\n",
      "  (out): Linear(in_features=100, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "embedding_dim, num_hiddens, num_layers = 100, 64, 1\n",
    "vocab_size=x_train_tokenize.size(0)\n",
    "net = RNN(vocab_size, embedding_dim, num_hiddens, num_layers)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(data_iter):\n",
    "            X, y = batch.text.int(), batch.label.int()\n",
    "            X = X.permute(1, 0)\n",
    "            y.data.sub_(1)  #X转置 y为啥要减1\n",
    "            if isinstance(net, torch.nn.Module):\n",
    "                net.eval() # 评估模式, 这会关闭dropout\n",
    "                acc_sum += (net(X).argmax(dim=1) == y).sum().item()\n",
    "                net.train() # 改回训练模式\n",
    "            else: # 自定义的模型, 3.13节之后不会用到, 不考虑GPU\n",
    "                if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\n",
    "                    # 将is_training设置成False\n",
    "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).sum().item() \n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_iter, test_iter, net, loss, optimizer, num_epochs):\n",
    "    batch_count = 0\n",
    "    with torchsnooper.snoop():\n",
    "        for epoch in range(num_epochs):\n",
    "            train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "            for batch_text, batch_label in train_iter:\n",
    "                #print(type)\n",
    "                X, y = batch_text.int(), batch_label.int()\n",
    "                print(X)\n",
    "                \n",
    "                x_tensor = X.int()\n",
    "                y_hat = net(x_tensor)\n",
    "                l = loss(y_hat, y)\n",
    "                optimizer.zero_grad()\n",
    "                l.backward()\n",
    "                optimizer.step()\n",
    "                train_l_sum += l.item()\n",
    "                train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "                n += y.shape[0]\n",
    "                batch_count += 1\n",
    "    \n",
    "            \n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print(\n",
    "            'epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "            % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n,\n",
    "               test_acc, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[   55,  1667,  1645,  1899,    80,  8068, 10786,  1154,    55,  1667,\n",
      "              2,  4429, 14185,     4,  1165,  3590,     6,  1660,    41,    31,\n",
      "           1140,   934, 10675,    72,   688,   934,    42,  1899,    80,  2763,\n",
      "           9687,     2,  1141,   506,  3411,  2998,    50,     0,    30,  8068,\n",
      "          10786,  1154,  1899,    80,  4929,  5625,     6,  1899,    80,  4929,\n",
      "           5773,     2,  7427,   182,    50,     0,  8068, 10786,  1154,  1899,\n",
      "             80,  7129, 18240,     2,  7813,  1077,  9291,  5625,     6,  1899,\n",
      "             80,    55,  1165,     2,  8371,  7962,     3,  1890,  1154,    55,\n",
      "           1667,  1645,  1899,    80,     2,    75,   218,    50,     0,  1899,\n",
      "             80, 14821,  7857,   137,   688,   934,   769,  1232,  7803,    11]]],\n",
      "       dtype=torch.int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Source path:... <ipython-input-95-fee6d4f4f76c>\n",
      "New var:....... train_iter = <torch.utils.data.dataloader.DataLoader object at 0x000002682037B7B8>\n",
      "New var:....... test_iter = <torch.utils.data.dataloader.DataLoader object at 0x000002682037B780>\n",
      "New var:....... net = RNN(  (rnn): RNN(100, 64)  (out): Linear(in_features=100, out_features=1, bias=True))\n",
      "New var:....... loss = CrossEntropyLoss()\n",
      "New var:....... optimizer = Adam (Parameter Group 0    amsgrad: False    bet...99)    eps: 1e-08    lr: 0.01    weight_decay: 0)\n",
      "New var:....... num_epochs = 5\n",
      "New var:....... batch_count = 0\n",
      "08:38:39.442111 line         4         for epoch in range(num_epochs):\n",
      "New var:....... epoch = 0\n",
      "08:38:39.442989 line         5             train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
      "New var:....... train_l_sum = 0.0\n",
      "New var:....... train_acc_sum = 0.0\n",
      "New var:....... n = 0\n",
      "New var:....... start = 1605832719.4429893\n",
      "08:38:39.442989 line         6             for batch_text, batch_label in train_iter:\n",
      "New var:....... batch_text = tensor<(1, 1, 100), int32, cpu>\n",
      "New var:....... batch_label = tensor<(1,), int64, cpu>\n",
      "08:38:39.447146 line         8                 X, y = batch_text.int(), batch_label.int()\n",
      "New var:....... X = tensor<(1, 1, 100), int32, cpu>\n",
      "New var:....... y = tensor<(1,), int32, cpu>\n",
      "08:38:39.447976 line         9                 print(X)\n",
      "08:38:39.454955 line        11                 x_tensor = X.int()\n",
      "New var:....... x_tensor = tensor<(1, 1, 100), int32, cpu>\n",
      "08:38:39.456262 line        12                 y_hat = net(x_tensor)\n",
      "08:38:39.459943 exception   12                 y_hat = net(x_tensor)\n",
      "Exception:..... RuntimeError: expected scalar type Int but found Float\n",
      "Elapsed time: 00:00:00.020941\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Int but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-77f5baccc70c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_DL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_DL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-95-fee6d4f4f76c>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_iter, test_iter, net, loss, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[0mx_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                 \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m                 \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-92-fbd31fb9bd0b>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# output, (h, c)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ana\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1692\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1693\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Int but found Float"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "lr, num_epochs = 0.01, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "train(train_DL, test_DL, net, loss, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torchsnooper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型设置与训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0代，训练损失:2201.834611511242,准确率23.35714340209961%\n",
      "第1代，训练损失:2201.834611511242,准确率23.35714340209961%\n",
      "第2代，训练损失:2201.8346115112427,准确率23.35714340209961%\n",
      "第3代，训练损失:2201.834611511242,准确率23.35714340209961%\n",
      "第4代，训练损失:2201.834611511242,准确率23.35714340209961%\n",
      "======= Training Finished ! =========\n"
     ]
    }
   ],
   "source": [
    "model=nn.Sequential(nn.Linear(100,70),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Linear(70,64),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Linear(64,4),\n",
    "                   nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion=nn.NLLLoss()\n",
    "\n",
    "optimizer=optim.SGD(model.parameters(),lr=0.005)\n",
    "epochs=5\n",
    "for e in range(epochs):\n",
    "    running_loss=0    #初始化损失\n",
    "    correct = 0\n",
    "    for words, labels in train_DL:\n",
    "        optimizer.zero_grad()  # 梯度置0\n",
    "        #print(words.size())\n",
    "        words=words.view(words.shape[0],MAX_SEQUENCE_LENGTH)\n",
    "        #print(words.size())\n",
    "        output=model.forward(words.float())\n",
    "        loss=criterion(output,labels)\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()   #累加损失\n",
    "        #print(running_loss)\n",
    "        predicted = torch.max(output.data,1)[1]\n",
    "        #print(predicted)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "        \n",
    "    else:  #打印平均损失结果\n",
    "        print(f\"第{e}代，训练损失:{running_loss/len(train_DL)},准确率{correct*100/14000}%\")   \n",
    "print(\"======= Training Finished ! =========\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=100, out_features=64, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=64, out_features=4, bias=True)\n",
       "  (5): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "images,labels=next(iter(train_DL))\n",
    "img=images[0].view(1,500)\n",
    "with torch.no_grad():\n",
    "    logits=model.forward(img.float())\n",
    "result=torch.softmax(logits,dim=1)\n",
    "result=result.data.numpy().squeeze()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 失败的RNN尝试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        combined = torch.cat(input, 1)\n",
    "        #hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    # 初始化第一个隐藏层输入\n",
    "    def initHidden(self):\n",
    "        return Variable(torch.zeros(1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "class Model:\n",
    "    def __init__(self,vocab_size, epoches=100):\n",
    "        \n",
    "        hidden_dim = 128\n",
    "        \n",
    "        output_dim = 4\n",
    "        self.model = RNN(vocab_size, hidden_dim , output_dim)\n",
    "        self.model.to(device)\n",
    "        self.epoches = epoches\n",
    "\n",
    "    def train(self,x_train,y_train):\n",
    "        loss_func = nn.CrossEntropyLoss().cuda()\n",
    "        optimizer = torch.optim.RMSprop(self.model.parameters(), lr=0.0003)\n",
    "\n",
    "        for epoch in range(self.epoches):\n",
    "            total_loss = 0\n",
    "            for i in range(len(y_train)):\n",
    "                x , y = x_train[i],y_train[i]\n",
    "                #embeding = nn.Embedding(len(vocab_list),300)\n",
    "                #x_tensor = torch.tensor([x], dtype=torch.long,device=device)\n",
    "                \n",
    "                #y_tensor = torch.tensor([y], dtype=torch.long, device=device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                hidden_dim = 128\n",
    "                hidden = Variable(torch.zeros(1, hidden_dim))\n",
    "                #output= self.forward(words.float(),hidden)\n",
    "                pred = self.model(x) # [batch, out_dim]\n",
    "                loss = loss_func(pred, y)\n",
    "                loss.backward()\n",
    "                total_loss += loss\n",
    "                optimizer.step()\n",
    "            print(\"Training: in epoch {} loss {}\".format(epoch, total_loss/1000))\n",
    "\n",
    "    def evaluate(self,x_dev,y_dev):\n",
    "        with torch.no_grad(): # 评估时不进行梯度计算\n",
    "            correct = 0\n",
    "            for i in range(len(y_dev)):\n",
    "                x , y = x_dev[i],y_dev[i] \n",
    "                # x_tensor = torch.tensor([x], dtype=torch.long,device=device)\n",
    "                x_tensor = embeds(x)\n",
    "                \n",
    "                pred = self.model(x_tensor)\n",
    "                if torch.argmax(pred).item() == y:\n",
    "                    correct += 1\n",
    "\n",
    "            print('Evaluating: test accuracy is {}%'.format(correct*100/len(y_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Variable' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-8a8f3f12d00a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_tokenize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#model.evaluate(x_dev_vectorized,y_dev_encoded)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-2be5901dffef>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x_train, y_train)\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mhidden_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m                 \u001b[1;31m#output= self.forward(words.float(),hidden)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# [batch, out_dim]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Variable' is not defined"
     ]
    }
   ],
   "source": [
    "model = Model(len(vocab_list),10)\n",
    "model.train(x_train_tokenize,train_y)\n",
    "#model.evaluate(x_dev_vectorized,y_dev_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): LSTM(500, 64, batch_first=True)\n",
      "  (out): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    #overload __init__() method\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=500,\n",
    "            hidden_size=64,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.out = nn.Linear(64,4)\n",
    "        \n",
    "    #overload forward() method\n",
    "    def forward(self, x):\n",
    "        r_out, (h_n, h_c) = self.rnn(x, None)\n",
    "        out = self.out(r_out[: ,-1, :])\n",
    "        return out\n",
    "rnn = RNN()\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01)\n",
    "#define cross entropy loss function\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 100])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 1, 500]' is invalid for input of size 100",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-fce2916f07b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;31m#print(b_x[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mwords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m#b_x = b_x.view(1, 10, 500).long()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[1, 1, 500]' is invalid for input of size 100"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    for words,labels in train_DL:\n",
    "        #recover x as (batch,time_step,input_size)\n",
    "        #print(b_x[0])\n",
    "        print(words.size())\n",
    "        words=words.reshape(words.shape[0],words.shape[1],500)\n",
    "        print(words.size())\n",
    "        #b_x = b_x.view(1, 10, 500).long()\n",
    "        #b_x = b_x.view(1, -1)[0].type(torch.LongTensor)\n",
    "        #print(words[0])\n",
    "        word=words.int()\n",
    "        #print(word[0])\n",
    "        #print(type(b_x))\n",
    "        #print(b_x)\n",
    "        output = rnn(word)\n",
    "        #print(rnn(b_x.long()))\n",
    "        #print(output[1])\n",
    "        loss = loss_func(output,labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % 50 == 0:\n",
    "            #train with rnn\n",
    "            test_output = rnn(test_x)\n",
    "            #loss function\n",
    "            pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "            #accuracy calculate\n",
    "            acc = float((pred_y == test_y).astype(int).sum()) / float(test_y.size)\n",
    "            print('Epoch: ', (epoch), 'train loss: %.3f'%loss.data.numpy(), 'test acc: %.3f'%(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-d3ff32aaa71a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# print 100 predictions from test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnumTest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtest_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnumTest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpred_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'prediction number'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_x' is not defined"
     ]
    }
   ],
   "source": [
    "# print 100 predictions from test data\n",
    "numTest = 100\n",
    "test_output = rnn(test_x[:numTest])\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:numTest], 'real number')\n",
    "ErrorCount = 0.0\n",
    "for i in pred_y:\n",
    "\tif pred_y[i] != test_y[i]:\n",
    "\t\tErrorCount += 1\n",
    "print('ErrorRate : %.3f'%(ErrorCount / numTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5、可视化训练信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\n5XKrnFnVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90\nbGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsT\nAAALEwEAmpwYAABFCklEQVR4nO3dd3hUVfrA8e+bTkggjR4g9CoECCBFARUFC1gQxAaWtWJd6+oq\novzsa1nLLioINsCGyIIFBEFATEDAEFqAAKGEkJBGCGnn98e9wSGmTMpkEvJ+nmee3Llt3rmZzJtz\nzj3niDEGpZRSylke7g5AKaVU3aKJQymlVIVo4lBKKVUhmjiUUkpViCYOpZRSFaKJQymlVIVo4lBV\nJiJLRGRSde/rTiKSICIXuOC8RkQ62sv/EZF/OrNvJV7nOhH5obJxKlUW0X4c9ZOIZDk89QdOAgX2\n89uNMZ/UfFS1h4gkALcaY5ZW83kN0MkYE19d+4pIBLAH8DbG5FdLoEqVwcvdASj3MMYEFC2X9SUp\nIl76ZaTqChHxNMYUlL+nqgqtqlKnEZHhIpIoIo+KyGFglogEi8giEUkWkWP2crjDMStE5FZ7ebKI\n/CIir9j77hGR0ZXct52IrBSRTBFZKiJvi8jHpcTtTIzPishq+3w/iEiYw/YbRGSviKSIyBNlXJ+B\nInJYRDwd1l0hIpvt5QEislZE0kTkkIi8JSI+pZzrQxF5zuH5w/YxB0Xk5mL7XiIiv4tIhojsF5Gp\nDptX2j/TRCRLRAYVXVuH4weLSLSIpNs/Bzt7bSp4nUNEZJb9Ho6JyAKHbWNFZKP9HnaJyCh7/WnV\ngiIy1fH3LCKf29c83f489Ch2Dd8VkcUichwYISKtReQrO8aUot+BiKSKyFkOxzYVkWwRaVLSe1Wl\n08ShStIcCAHaArdhfU5m2c/bACeAt8o4fiCwHQgDXgI+EBGpxL6fAr8BocBU4IYyXtOZGK8FbgKa\nAj7AQwAi0h141z5/S/v1wimBMWYdcBw4r9h5P7WXC4AH7PczCDgfuKuMuLFjGGXHMxLoBBRvXzkO\n3AgEAZcAd4rI5fa2c+2fQcaYAGPM2mLnDgH+B7xpv7d/Af8TkdBi7+Ev16YE5V3nj7CqPnvY53rN\njmEAMAd42H4P5wIJpbxGcUuwrklTYANQvBr1WmA6EAisBRYBe4EIoBUw1xiTC8wFrnc4biKwzBiT\n7GQcqogxRh/1/IH1B3yBvTwcyAX8ytg/Ejjm8HwFVlUXwGQg3mGbP2CA5hXZF+tLKR/wd9j+MfCx\nk++ppBifdHh+F/CdvfwU1pdL0baG9jW4oJRzPwfMtJcDsb7U25ay7/3A1w7PDdDRXv4QeM5engm8\n4LBfZ8d9Szjv68Br9nKEva+Xw/bJwC/28g3Ab8WOXwtMLu/aVOQ6Ay2AQiC4hP3+WxRvWZ8/+/nU\n0n7PWEnHAI0druEch+2DgGTHa+GwbSCwjz/bdmOA8dX991QfHlriUCVJNsbkFD0REX8R+a9dlZOB\nVTUS5FhdU8zhogVjTLa9GFDBfVsCqQ7rAPaXFrCTMR52WM52iKml47mNMceBlNJeC6t0caWI+AJX\nAhuMMXvtODrb1TeH7Tj+D6v0UZ7TYsD6j9nx/Q0UkeV29Us6cIeT5y06995i6/Zi/TdepLRrc5py\nrnNrrN/ZsRIObQ3scjJex9fzFJEX7KqtDP4spTi+d8fr1hrYa0polzNWaTEbGC4iXYGOwMKKxqS0\nqkqVrPitdn8HugADjTGN+LNqpLTqp+pwCAgREX+Hda3L2L8qMR5yPLf9mqGl7WyMicP64h3N6dVU\nYFV5bcO6G6oR8I/KxIBV4nL0KdaXXGtjTGPgPw7nLe/WyINYVUuO2gAHnIiruLKu836s31lQCcft\nBzqUcs7jWKXNIs0dlq8FxmJV3TXGKl0VvV4Rx/e/H2gjIqXd+DMbq7rqBuALx3+QlPM0cShnBGLV\nZafZ9eVPu/oF7f/gY4CpdsPmIOAyF8X4BXCpiAy1G7KnUf7fxqfAfVhfnJ8XiyMDyLL/q73TyRjm\nA5NFpLuduIrHH4j133yO3V5wrcO2ZKwqovalnHsx0FlErhURLxGZAHTHaguoqFKvszHmEFZ7xDt2\nI7q3iBQllg+Am0TkfBHxEJFW9vUB2AhcY+8fBYwr9nonsUqA/lgluLL8hpWEXxCRhiLiJyJDHLZ/\nDFyBlTzmVPjdK0ATh3LO60AD4CjwK/BdDb3udVh11ilY7QrzsL5ESvI6lYzRGLMFuBsrGRwCjgGJ\n5Rz2GTAM+MkYc9Rh/UNYX+qZwHt2zM7EsMR+Dz8B8fZPR3cB00QkE6tNZr7DsdlYjcOrxbqb6+xi\n504BLsUqLaQAjwCXFovbWa9T9nW+AcjDKnUdwWrjwRjzG1bj+2tAOvAzf5aC/olVGjkGPMPpJbg5\nWKW7A0Cc/ZqlMtatuJdhVUPtw/o9TnDYvh+rgd0Aq5x7y6o47QCo6gwRmQdsM8a4vMSjzlwiMhM4\naIx50t2x1FWaOFStJSL9gVSsXtEXAguAQcaY390Zl6q7xOplvxHoY4zZ495o6i6tqlK1WXOsW0Wz\nsPog3KlJQ1WWiDwLxAIva9KoGi1xKKWUqhAtcSillKqQejHIYVhYmImIiHB3GEopVaesX7/+qDHm\nL2N51YvEERERQUxMjLvDUEqpOkVEio84AGhVlVJKqQrSxKGUUqpCNHEopZSqEE0cSimlKkQTh1JK\nqQrRxKGUUqpCNHEopZSqEE0cSil1hskvKGTNrqM8uyiO3PzCaj9/vegAqJRSZ7rcfCtZfBd7mB/i\nkkg9nouftwdX9GlFz1aNq/W1NHEopVQdlZNXwModyXwXe5gftyaRmZNPgK8X53VtyuiezRnWpQn+\nPtX/Na+JQyml6pCsk/ks33aE72IPs3z7EbJzC2jcwJuLejRndM/mDOkYhp+3p0tj0MShlFK1XHp2\nHku3JrEk9jArdyaTm19IWIAPl/dpxeiezTm7fSjenjXXZK2JQymlahljDInHTvBL/FGWxB5mTfxR\n8gsNLRr7ce2ANozu2ZyoiBA8PcQt8WniUEopNzPGsCs5i3V7UvnNfhxKzwGgbag/t5zTjtE9W9A7\nvDEi7kkWjjRxKKVUDSsoNGw9lHEqSUQnpJJyPBeAJoG+DGgXwsB2IQxsF0rnZgG1Ilk40sShlFIu\nlptfyB8H0k6VKNYnHCPzZD4ArUMaMLxLUwa2C6F/uxAiQv1rXaIoThOHUkpVo8ycPPamZLM3JZvt\nSZlE70llw75jnLQ74nVsGsBlkS2tRBERQsugBm6OuOI0cSilVAWlZ+eRkHKchJTj7E3JPvVzb8px\njmblntrPQ6B7y0ZcN7AtA9oFExURQliArxsjrx6aOJRSqhhjDKnHc9mbaiWDhKP2Tzs5HMvOO23/\nFo39aBvqzwXdmtE2tCERof60DW1I21B/GvqeeV+zLn1HIjIKeAPwBN43xrxQbHtbYCbQBEgFrjfG\nJNrbXgQusXd91hgzz17/ARAFCLADmGyMyXLl+1BKnXnyCwo5lJ5jlRRSj7MvJZt9qVYV077UbLLs\nNggAEWjZuAERYf6MPqvFqcQQYScHV3e4q21cljhExBN4GxgJJALRIrLQGBPnsNsrwBxjzGwROQ94\nHrhBRC4B+gKRgC+wQkSWGGMygAfsn4jIv4ApwGkJSSmlALJz8/9MBnaC2JuSzf7UbBKPnSC/0Jza\n18fTg/CQBrQJ8ad/RDBtQhvSNsSfiDB/woPrX3IoiytLHAOAeGPMbgARmQuMBRwTR3fgQXt5ObDA\nYf1KY0w+kC8im4FRwHyHpCFAA8CglFJYYzdFJ6SyaudRVu08ytZDGadtb+TnRdvQhvRo1ZiLz2pB\nmxB/2tilh+aN/NzWoa6ucWXiaAXsd3ieCAwsts8m4Eqs6qwrgEARCbXXPy0irwL+wAgcEo6IzAIu\nttf9vaQXF5HbgNsA2rRpUw1vRylV2xQWGrYezuAXO1H8lpBKbn4h3p5Cv7bBPHBBZ9o3aUibEH/a\nhvoT5O/j7pDPCO5utXkIeEtEJgMrgQNAgTHmBxHpD6wBkoG1QEHRQcaYm+yqsH8DE4BZxU9sjJkB\nzACIiorSUolSZ4jD6Tms2pnML/FH+WXn0VMd5zo3C+D6gW05p3MYA9uFuGRUWGVx5ZU9ALR2eB5u\nrzvFGHMQq8SBiAQAVxlj0uxt04Hp9rZPsRrCHY8tsKu/HqGExKGUOjMcP5nPuj0prNppJYqdR6x7\nYcICfDinUxhDOzVhaMcwmjf2c3Ok9YcrE0c00ElE2mEljGuAax13EJEwINUYUwg8jnWHVVHDepAx\nJkVEegG9gB/sdo0Oxph4e3kMsM2F70Ep5QY5eQV8s/EAX/9+gPV7j5FXYPD18mBAuxCujgpnaMcm\ndG0eiIe2SbiFyxKHMSZfRKYA32PdjjvTGLNFRKYBMcaYhcBw4HkRMVhVVXfbh3sDq+xu9xlYt+nm\ni4gHMFtEGmHdjrsJuNNV70EpVbOSMnL4aO1ePv1tH6nHc+nYNICbh7bjnI5NiIoI1jubagkx5syv\n/o+KijIxMTHuDkMpVYpN+9OYtXoPizYfosAYLujWjJuGRDCofWitH7fpTCYi640xUcXXa+uRUsot\n8gsK+X5LEjNX72H93mME+Hpx46AIJg1uS9vQhu4OT5VBE4dSqkalZecyN3o/c9YkcDA9h7ah/jx9\nWXfG9Qsn0M/b3eEpJ2jiUErViPgjmcxancCXGxLJyStkcIdQnhnbk/O6NtWOd3WMJg6llMsUFhpW\n7kxm5uoEVu5IxsfLg8sjW3LTkHZ0a9HI3eGpStLEoZSqsPyCQtJP5JF2Io/0E3mkZ1s/07JzT1u3\nMTGN3cnHaRroy99HdubagW0IPQOGFa/vNHEoVY8ZY8jIyefY8VxSs3NJy84l9Xgex47ncizbelgJ\nwXqk20nBceTYkgT6etGogTetghtw73mduPisFvh4edTQu1KupolDqTNQYaFhe1ImcQczOJadS6qd\nCKyfjokhj4LCkm/J9/YUgvx9CGrgTeMG3rQM8qNri0CCGvgQ5G+tC/L3plED71P7BPn70MjPCy9P\nTRJnMk0cSp0BjDHsS81mdXwKq3cd5dddKafGcALw8hCCG/oQ4u9DcENvOjYNcHjuQ7C/96nnIQ2t\nxBDg66V9KFSJNHEoVUcdycxh7a4UVscfZXV8CgfSTgDQrJEvwzo3YVCHUPq1DaZJoK8mAVWtNHEo\nVUdk5OSxbncqq+OPsmbXUXYkWYP9NfLzYlCHUG4f1p7BHcLo0KShJgnlUpo4lKql8goKid6Tyupd\nVolic2IahQb8vD3oHxHCFX3CGdIxlB4tG2s/CFWjNHEoVQtFJ6TyxNd/sCMpC08PIbJ1EFNGdGRw\nxzD6tAnC10sH+1Puo4lDqVok9XguLyzZyvyYRFoFNeDNiX04r2tTAnz1T1XVHvppVKoWKCw0fLE+\nkeeXbCUzJ587hnXg3vM76ix2qlbST6VSbrb9cCZPLviD6IRj9I8I5rnLz6JL80B3h6VUqTRxKOUm\n2bn5vLFsJx+s2kOgnxcvXdWLcf3CdVY7Vetp4lDKDX6MS2Lqwi0cSDvB+KhwHhvdjZCGPu4OSymn\naOJQqgYdSDvB1IVb+DEuic7NAvj8jkH0jwhxd1hKVYgmDqVqQF5BITN/2cPrS3cC8NjortwytB3e\nOqaTqoM0cSjlYjEJqTzxdSzbkzK5oFtTpo7pQXiwv7vDUqrSNHEo5SJp2bm8sGQbc6P307KxHzNu\n6MeFPZq7OyylqkwTh1LVzBjDos2HeObbLRzLzuP2c9tz7/mdaKid+NQZQj/JSlWjw+k5PLkglqVb\nk+gV3pg5Nw+ke0udIlWdWTRxKFUNCgsNn0Xv44XF28grLOSJi7tx05AIndBInZE0cShVRXuOHuex\nLzezbk8qg9qH8sJVZ9E2tKG7w1LKZTRxKFVJ+QWFvLdqD68v3YGPlwcvXnUW46Na61wY6oyniUOp\nSog9kM6jX25my8EMLurRjGlje9KskZ+7w1L1iTGQkw7ZKZCdCtlH7WWHx/EUuOwNCGxWrS+tiUOp\nCsjJK+CNZTuZsXI3wf4+vHtdX0af1cLdYakzTdYRSIqFozvh+FGHpJB6emIozC/5eE8f8A8D/1DI\nzQI0cSjlFut2p/DYV3+w5+hxxkeF88TF3Wns7+3usFRdlpcDR7dD0hb7EWv9PJ7ssJNAg2BoaCeC\nkPYQHvVnYih6NHRY9gkAF1aZauJQqhyZOXm8sGQbn6zbR+uQBnx8y0CGdgpzd1iqLjEGMg6cnhyS\ntlglClNg7ePlB026QqeLoFkP69Gkq5UwPGrXjI+aOJQqw9K4JJ5cEMuRzBxuHdqOBy/srJMrqfKd\nSIPdK2Dv6j+TRU76n9sbt7ESQ9dL7STR0ypJeNaNz1bdiFKpGlZYaHjm2y3MXruXLs0C+c8N/Yhs\nHeTusFRtVVgABzbArmUQvwwOxIApBO+GVmLoceWfCaJpN2gQ5O6Iq0QTh1LF5BcU8vAXm/n69wPc\nMrQdj47qio+XduRTxaQf+DNR7F4BOWmAQMs+cM7focP5VluE55nXDqaJQykHJ/MLuOfT3/khLomH\nL+rCXcM7aL8MZck7YVU9xf9kJYzkbdb6gObQ9RLocB60H2E1Up/hNHEoZcvOzef2j9azaudRpl7W\nnclD2rk7JOUOhYWQn2M9Mg/DLjtR7F1jrfP0hbaDIPI66Hg+NO3u0juYaiNNHEoB6SfyuPnDaH7f\nd4xXru7NuH7h7g5JVdWelbBlAeRl24ngZPk/805AYd5fzxXWGfrdZCWKtkPAp37Pp6KJQ9V7R7NO\ncuMHv7HzSCZvX6sd+uq8Axtg2TTYvRx8G1kN0V5+4OVr//Sz+kWctq6knw3ArzFEDIWg1u5+V7WK\nJg5Vrx1KP8F176/jYNoJ3p/Un2Gdm7g7JFVZydvhp+dg60JoEAIX/R9E3QLeOhRMdXPprSIiMkpE\ntotIvIg8VsL2tiKyTEQ2i8gKEQl32PaiiMTajwkO6z+xzxkrIjNF5My7ZUHViISjxxn37lqSM04y\n5+aBmjTqqrR9sOBueOds2LUchj8O922CQXdr0nARl5U4RMQTeBsYCSQC0SKy0BgT57DbK8AcY8xs\nETkPeB64QUQuAfoCkYAvsEJElhhjMoBPgOvt4z8FbgXeddX7UGem7Yczuf6DdeQXFPLZbWfTs1Vj\nd4ekKiorGVa9AjEzAYGz74KhD9aLu5rczZVVVQOAeGPMbgARmQuMBRwTR3fgQXt5ObDAYf1KY0w+\nkC8im4FRwHxjzOKig0XkN0BbMVWFbNqfxqRZv+Hr5cH82wfRqVmgu0NSFZGTDmv+DWvfsRq1+1wH\nwx6FxvpVUFNcWVXVCtjv8DzRXudoE3ClvXwFECgiofb6USLiLyJhwAjgtNYpu4rqBuC7kl5cRG4T\nkRgRiUlOTi5pF1UP/bo7hWvf+5VAPy++uGOwJo26JO8ErH4D3ugNK1+GzhfC3etgzL81adQwdzeO\nPwS8JSKTgZXAAaDAGPODiPQH1gDJwFqgoNix72CVSlaVdGJjzAxgBkBUVJRxTfiqLlm+7Qh3fLye\nNiH+fHTLQJo31vrvOqEgD37/CH5+CTIPQccL4Lx/QstId0dWb7kycRzg9FJCuL3uFGPMQewSh4gE\nAFcZY9LsbdOB6fa2T4EdRceJyNNAE+B214WvziSLNh/k/rkb6daiEbNvHkBIQx93h6TKU1gIW76C\n5dMhdTe0HghXfQARQ9wdWb3nysQRDXQSkXZYCeMa4FrHHexqqFRjTCHwODDTXu8JBBljUkSkF9AL\n+MHeditwEXC+fZxSZZofvZ/HvtpMVNsQ3p8cRSM/vRGvVss/CZvnw5o34egOa2DAifOg80X1rod2\nbeWyxGGMyReRKcD3gCcw0xizRUSmATHGmIXAcOB5ETFYVVV324d7A6vsMYIygOvthnKA/wB7gbX2\n9q+MMdNc9T5U3fbBL3t4dlEcwzo34T/X96OBT+2a10A5yMmA9R/Cr+9YVVLNz4JxM6H7FeChg0zW\nJmLMmV/9HxUVZWJiYtwdhqohyZknWb7tCD/EHWbp1iNcfFZzXp/QR0e4ra2yjsCv70L0B3AyHdqd\nC0PutwYN1BKGW4nIemNMVPH17m4cV6rKjDHEHcrgp61HWLrtCJv2pwHQorEfd4/owAMXdMbLU5NG\nrZO627qt9vdPoCAXul0GQ++HVv3cHZkqhyYOVSfl5BWwdlcKS7cm8dO2IxxKz0EEeocH8feRnTm/\nWzO6tQjUIdFro4MbYfXrEPcNeHhB74kw+F4I6+juyJSTNHGoOiMpI4efth1h2dYjrI4/yom8Avx9\nPDmnUxgPjOzMiC5NaRLo6+4w3S871fpS/uNza07rNmdD++HWI6S9e6p/jIE9P8Mvr1mTHvk2spLF\n2XdCYPOaj0dViSYOVWsVFhq2HMxg2bYklm09wh8HrDmbWwU1YHxUOOd1a8bZ7UPw9dIGb/JOwI7v\nYPPnsPMHa2jwsM7Qfpg1j8TWhdZ+jdtY69oPh3bDIMDF43MVFliv/cvrcGgjBDSDC6ZC1M3WyLOq\nTtLEoWqNE7kFbEpMY/3eY6zfe4wN+46Rlp2HCPRtE8wjo7pwftdmdG4WoFVQYH0p71lplSy2fgsn\nM6zZ6AbcBr3GQ4veVunCGEjZZQ0zvnsFxC20OtSBdatrUWmkzSDwDah8LJmHrQEH0/dbP9P2QcIq\nqy0jpD1c9gb0ukYHHjwD6F1Vym2OZOQQYyeJmL3H2HIgnfxC6/PYsWkA/doEM7B9CMM6NyE0QKug\nACsJHNpolSxiv4Ssw+ATCN3HwFlXW3ckeZRTAisssM6xe4X12Per1Tjt4Q2tB/yZSFr2BU/7f8uC\nPMg4YCeE/acnh7R91rbC/NNfxz8MmnSFAX+zGr7Li0vVOqXdVaWJQ9WIgkLDjqRMYvYeY8PeY8Ts\nTWV/6gkAfL086N06iKi2wfRrG0zfNsEEa8/u06XugT++gM3zIGWn9SXf6ULodTV0HgXeDSp/7txs\n2P/rn4nk0GbAWAmpSRerT0XmITitv61YbRONW0NQG2uio8atIaitvRwOPg2r9p6V2+ntuKrGxR3M\n4Me4JGL2prJxXxqZJ63/SJsE+hLVNphJgyKIigihe4tG2seiJFnJELfA6kWd+Ju1ru0Qa56J7mPB\nP6R6XsfH3+oz0eE863l2qlUFtnsFpMRbpZjGra2EENTGWm4cbs2Sp+olTRyqWuXmF/LdlsPMWZNA\nzN5jiECXZoGMiWxJVEQwUW1DCA9uoG0Upck4BNsWWXdF7V1t/ZfftIfVoNxzXM1MYeofAj0utx5K\nlUATh6oWSRk5fLJuH5/9to/kzJO0DfXnyUu6cVXfcK12Kk96otW4HfeN1d6AsdoGzn3YKlk06+Hu\nCJU6jSYOVWnGGH7bk8qctXv5fsthCoxhRJem3DioLed2aoKHh5YqSnVsr3Wbatw3kBhtrWvWE0b8\nA7qNgaZd3RufUmXQxKEq7PjJfBZsPMBHa/ey7XAmjRt4c9OQCK4/uy1tQ7VBtFQpu/5MFgd/t9a1\n6A3nPwXdxmrPaVVnlJs4ROQy4H86hLnanZzFR7/u5Yv1iWTm5NO9RSNevOosxvRupaPOluboTquB\nO+4bOPyHta5VFIycZpUsQtq5NTylKsOZEscE4HUR+RJraPRtLo5J1SIFhYbl244w59e9rNyRjLen\nMLpnCyYNbkvfNsHayF2arGRYdL/V0A3Q+my46HmrP0NNNHAr5ULlJg5jzPUi0giYCHxoz50xC/jM\nGJPp6gCV+3y1IZF//biDxGMnaNbIlwdHduaaAa1pGqg9f8u07X+w8F44mQkjnoQ+10Gjlu6OSqlq\n41QbhzEmQ0S+ABoA9wNXAA+LyJvGmH+7MD7lBtm5+fxzwRa+3JBI79ZB/OPibozs3gxvHZq8bDkZ\n8P3j8PvH1iREVy6Cpt3cHZVS1c6ZNo4xwE1AR2AOMMAYc0RE/IE4QBPHGWRHUiZ3fbKBXclZ3Hd+\nJ+49vxOeendU+RJWw4I7rFtrz3kIhj0KXnobsjozOVPiuAp4zRiz0nGlMSZbRG5xTVjKHT6P2c8/\nv4klwNeLj28ZyJCOYe4OqfbLPwk/PQtr3rIaum/+3hrvSakzmDOJYypwqOiJiDQAmhljEowxy1wV\nmKo5jlVTg9qH8sY1kTRtpO0Y5Tr8B3x1GxyJs4YJH/ls5UeXVaoOcSZxfA4MdnheYK/r75KIVI3a\naVdNxSdnce/5nbhPq6bKV1gAq9+A5f9nDc9x3RfQaaS7o1KqxjiTOLyMMblFT4wxuSKilbdngC/X\nJ/Lkglga+nry0c0DGdpJq6bKlbobvr7TGk22++Vw6WvVN9igUnWEM4kjWUTGGGMWAojIWOCoa8NS\nrnQit4Cnvonl8/WJDGwXwpsT+9BMq6bKZgxsmA3f/cOaJ/vK96z5L7Qfi6qHnEkcdwCfiMhbgAD7\ngRtdGpVymZ1Jmdz96QZ2Hsni3vM6cu/5nfDS22zLlpkEC++Bnd9b061e/o41rLhS9ZQzHQB3AWeL\nSID9PMvlUSmXKKqa8vfxZM7NAzink4vnmz4TxH0D394Pedkw6kVrWlYPTbSqfnOqA6CIXAL0APyK\nhpgwxkxzYVyqGp3ILeDphbHMj9GqKacVFlqd+db9B1pEWlVTTTq7OyqlagVnOgD+B/AHRgDvA+OA\n31wcl6om8Uesu6Z2HsliyoiO3H+BVk2VqyAfFk6BTZ/B2XdZAxJ6ers7KqVqDWdKHIONMb1EZLMx\n5hkReRVY4urAVNV9F3uIB+dvws/bkw9vGsCwzlo1Va78k/DFzdbghOc9afUC1wZwpU7jTOLIsX9m\ni0hLIAVo4bqQVHVYtTOZez77nZ6tGvPudf1o3lirpsqVexzmXge7l8Pol2Dg7e6OSKlayZnE8a2I\nBAEvAxsAA7znyqBU1fyRmM4dH62nQ5MAZt88gEZ+Ws1SrhNp8Ol4aza+y9+FyGvdHZFStVaZiUNE\nPIBlxpg04EsRWQT4GWPSayI4VXEJR48zedZvBPn7aNJwVlYyfHQFJG+Dq2dD9zHujkipWq3MVlJ7\n1r+3HZ6f1KRRex3JzOHGmb9RaAxzbhmgd045Iz0RZo2ClHi4dp4mDaWc4MztNctE5CrRqd5qtayT\n+dw0K5rkzJPMnNyfDk10sL1ypeyCmaMg6wjcuAA6nu/uiJSqE5xp47gdeBDIF5EcrN7jxhjTyKWR\nKafl5hdyx0fr2XY4k/cnRdGnTbC7Q6r9Dsda1VOmECYvgha93R2RUnWGMz3HA2siEFU5hYWGhz7f\nxC/xR3nl6t6M6NLU3SHVfvuj4ZOrwCcAbligHfuUqiBnOgCeW9L64hM7qZpnjOG5/21l4aaDPDqq\nK+P66fhJ5dq9Aj67FgKbwY3fQFAbd0ekVJ3jTFXVww7LfsAAYD1wnksiUk7778rdzFy9h5uGRHDH\nsPbuDqf22/Y/+HwyhHa0ShqBzdwdkVJ1kjNVVZc5PheR1sDrrgpIOefL9Ym8sGQbl/ZqwT8v6Y7e\nu1COTfNgwZ3QMtKaeEnn0FCq0iozaFEi0M2ZHUVklIhsF5F4EXmshO1tRWSZiGwWkRUiEu6w7UUR\nibUfExzWT7HPZ0SkXs48tHz7ER75cjNDOoby6vjeeOiMfWX77T34+jZoO9iqntKkoVSVONPG8W+s\n3uJgJZpIrB7k5R3nidUHZCRWsokWkYXGmDiH3V4B5hhjZovIecDzwA32aLx97dfyBVaIyBJjTAaw\nGlgErHDmDZ5pNu5P466PN9C1eSD/ub4fvl6e7g6pdlv1L1j2DHQeDVd/CN7at0WpqnKmjSPGYTkf\n+MwYs9qJ4wYA8caY3QAiMhcYCzgmju5Yt/oCLAcWOKxfaYzJx7oNeDMwCphvjPndPp8TIZxZdidn\ncfOH0YQF+jDrpv4Eaq/wkmWnwvbFEPsV7FpmzdR3+bs6wq1S1cSZxPEFkGOMKQCrJCEi/saY7HKO\na4U1W2CRRGBgsX02AVcCbwBXAIEiEmqvf9oeibdoSPc4KkBEbgNuA2jTpu7fOXMkw+oVLsBHNw+k\naaD+53yazCRrRNutC2HPKjAF0LgNDP8HnPuwTr6kVDVyJnEsAy4Aimb+awD8AAyuhtd/CHhLRCYD\nK4EDQIEx5gcR6Q+sAZKBtUBBRU5sjJkBzACIiooy5exeq2Xk5DFpVjSpx3OZe9vZRIQ1dHdItUN6\nImz9FuIWwr61gIGQDjDkXug2Blr20SHRlXIBZxKHn+N0scaYLBHxd+K4A0Brh+fh9rpTjDEHsUoc\n2FPTXmUPqIgxZjow3d72KbDDidc84+TkFXDbnBh2JmUyc3J/eoUHuTsk90rdbSWKrQvhwHprXdPu\nMOxRa5yppt01WSjlYs4kjuMi0tcYswFARPoBJ5w4LhroJCLtsBLGNcBpY1Xbd0Wl2oMpPg7MtNd7\nAkHGmBQR6QX0wirl1CsFhYYH52/k192pvD4hknPr60RMR7ZZiSJuIST9Ya1rEQnnPwXdxkJYR7eG\np1R940ziuB/4XEQOYo1T1RyYUOYRgDEmX0SmAN8DnsBMY8wWEZkGxBhjFgLDgedFxGBVVd1tH+4N\nrLIbwDOA6+2GckTkXuARO47NIrLYGHOrk++3Tnn5++0s/uMwT1zcjcv7tHJ3ODUn/yTs+9Vq2N7+\nHRzdbq1vPRAunA7dLoPgtu6NUal6TIwpv/pfRLyBLvbT7caYPJdGVc2ioqJMTExM+TvWIn8kpjP2\n7V8YH9WaF67q5e5wXMsYa6TaXcsgfhkk/AJ5x8HDC9oMgu5joeul0EgnnlSqJonIemNMVPH1zvTj\nuBv4xBgTaz8PFpGJxph3XBCnAvILCnn8682EBvjy+MVO9bWse3LSYc9KK1HsWgZp+6z1we0gciJ0\nOB/anQO+OsamUrWNM1VVfzPGOE7mdExE/gZo4nCR2Wv3Ensgg7eu7UPjBmdI34PCQjj0O8T/ZCWK\n/b9Zt8z6BEC7c2HwvdZ8GCE65pZStZ0zicNTRMTYdVp2w7WPa8Oqvw6mneDVH7YzvEsTLjmrjlfN\nZKfC9iVWoti1HE6kWutbRMKQ+6xEET4AvPTjpFRd4kzi+A6YJyL/tZ/fDixxXUj129MLt1BoDM+O\n7Vl3e8cfPwpr/g3R70NuFgQ0g84XWdVPHUZAw3o5xJhSZwxnEsejWD2w77Cfb8a6o0lVs+9iD/Nj\nXBKPj+5K6xBnusrUMplJsOZNiJkJeSeg55UwaIp2xFPqDOPMsOqFIrIO6ACMB8KAL10dWH2TmZPH\n1IVb6No8kJuHtnN3OBWTcRBWvwHrP4SCXGtsqHMe0pn1lDpDlZo4RKQzMNF+HAXmARhjRtRMaPXL\nqz/sICkzh3ev74u3Zx0ZVyltP6x+HTbMsebu7nUNnPMghHZwd2RKKRcqq8SxDVgFXGqMiQcQkQdq\nJKp6ZtP+NGavTeCGs9vSp02wu8Mp37EEa7jyjZ9az/tcB0MfgOAId0allKohZSWOK7GGCVkuIt8B\nc7F6jqtqlF9QyD++/oMmAb48dFGX8g9wp5RdsOpV2DQXPDyh32QYej801rnOlapPSk0cxpgFwAIR\naYg1j8b9QFMReRf42hhT78aOcoUP1ySw5WAG71zXl0a1dX6N5O2w8hWI/QI8fWDg7Va/C+3JrVS9\n5Ezj+HHgU+BTEQkGrsa600oTRxUlHsvm1R92cF7XpozuWQtvVEvdA8umwZavwbsBDLobBt0Dgc3c\nHZlSyo2cuR33FGPMMaw5Lma4Jpz6wxjD099sAWDa2B61r89GxkH48BJraJChD1hJQ/tfKKWoYOJQ\n1ef7LYdZtu0IT1zcjfDgWtZn42QmfDoecjLg5u+heU93R6SUqkU0cbhBRk4eTy/cQrcWjbhpSIS7\nwzldQT58fhMkxcF18zVpKKX+QhOHG7z6/XaOZJ7kvzdE4VWb+mwYA0sehvgf4bI3oOMF7o5IKVUL\n1aJvrfph4/405vy6l0mDIohsHeTucE5XNFzI0AetW22VUqoEmjhqUH5BIY9/9QdNA335+4W1bDiO\n2K/gx6eg51Vw3j/dHY1SqhbTqqoaNHP1HrYeyuA/1/clsDb12dj3K3x9hzXb3th3wEP/n1BKlU6/\nIWrI/tRsXvtxJxd0a8pFPWpRn42UXfDZRKv39zWfgrefuyNSStVymjhqgDGGp76JRQSeqU3zbBxP\ngU/GWUOeX/c5+Ie4OyKlVB2giaMGLIk9zPLtyTw4sjOtghq4OxxLXg7MnQjpB2DiXB3RVinlNG3j\ncLEMe56NHi0bMXlwhLvDsRQWwoI7YP86uHo2tB7g7oiUUnWIJg4Xe/m77RzNOsn7k2pRn41lz1jj\nT418Fnpc7u5olFJ1TC35Jjszbdh3jI/X7eXGQRH0Cg9ydziWmJnW5EtRt8Dge9wdjVKqDtLE4SIF\nhYYnv46lWaBf7ZlnY+eP8L+HoNOFMPolnQdcKVUpmjhc5NN1e4k7lME/L+1OgG8lawQLCyDvRPUE\ndGgzfD4ZmvWAcbPAU2splVKVo98eLpCSdZKXv9/O4A6hXHxWFfpszL8Rti+GsM7QIhJaRkKL3tC8\nF/gGOH+e9APWaLd+jeHa+RU7VimlitHE4QKv/LCd7NwCnhlThXk2dnwP2xZB10uhMB92r4DNc+2N\nAmGdHJJJJLToBb6Bfz1PToaVNE5mwS3f66x9Sqkq08RRzTbtT2Nu9H5uGdKOTs1K+CJ3Rl4OLHnU\nKmmMmwVePtb6zMNwcCMc2mj9TFgFf8y3DxKrL4ZjMmnWA768FZK3WR38mvWo4rtTSilNHNWqsNDw\n1MIthAX4ct8FnSp/orVvwbE9cMPXfyYNgMDm0GWU9SiSmWQlkkObrGSyb601N7ijMf+GDudVPh6l\nlHKgiaMafbE+kU3703htQu/KD2KYngirXrWqqJz5sg9sBoEXQeeL/lyXdeTPRBLSDs4aV7lYlFKq\nBJo4qkl6dh4vfLeN/hHBXB7ZqvIn+uFJMIVw0f9V/hwBTaHTSOuhlFLVTG/HrSb/+nE7adm5TK1K\ng/ielVaP7qEPQHDb6g1QKaWqiSaOahB3MIOPft3L9We3pUfLxpU7SUGe1SAe1AaG3Fe9ASqlVDXS\nqqoqMsbw9MJYgvx9eHBkFWb1i34fjsTBhE/Au5aMoKuUUiXQEkcVfbPxINEJx3jkoi4E+fuUf0BJ\nspJh+fNWY3jXS6o3QKWUqmaaOKogMyeP6Yu30ju8MeOjWlf+RMumQl62jh+llKoTNHFUwb9/iudo\n1kmmje2Jh0clv/ATY+D3j+HsO63e4EopVcu5NHGIyCgR2S4i8SLyWAnb24rIMhHZLCIrRCTcYduL\nIhJrPyY4rG8nIuvsc84TkUrWD1VN/JFMZv6yhwlRrendOqhyJykshMUPQ0BzGPZItcanlFKu4rLE\nISKewNvAaKA7MFFEuhfb7RVgjjGmFzANeN4+9hKgLxAJDAQeEpFG9jEvAq8ZYzoCx4BbXPUeSmM1\niG/B38eTh6syZPrGj+HgBrjw2ZLHmVJKqVrIlSWOAUC8MWa3MSYXmAuMLbZPd+Ane3m5w/buwEpj\nTL4x5jiwGRglVgeJ84CiMTVmA5e77i2UbEnsYVbHp/DQRV0IDfCt3ElOHIOlU6HNIDjr6mqNTyml\nXMmViaMVsN/heaK9ztEm4Ep7+QogUERC7fWjRMRfRMKAEUBrIBRIM8bkl3FOAETkNhGJEZGY5OTk\nanlDANm5+Ty3KI5uLRpx7YA2lT/R8uet5KEN4kqpOsbdjeMPAcNE5HdgGHAAKDDG/AAsBtYAnwFr\ngYKKnNgYM8MYE2WMiWrSpEm1BfzO8l0cTM9h2tgelZ9D/HAsRL8HUTdbw6ErpVQd4srEcQCrlFAk\n3F53ijHmoDHmSmNMH+AJe12a/XO6MSbSGDMSEGAHkAIEiYhXaed0pYSjx5mxcjdX9GlF/4iQyp3E\nGFjyCPgFwYgnqjU+pZSqCa5MHNFAJ/suKB/gGmCh4w4iEiYiRTE8Dsy013vaVVaISC+gF/CDMcZg\ntYUUDfc6CfjGhe/hNNMWxeHj5cHjo7tW/iSxX8Le1XD+U+BfyeSjlFJu5LLEYbdDTAG+B7YC840x\nW0RkmoiMsXcbDmwXkR1AM2C6vd4bWCUiccAM4HqHdo1HgQdFJB6rzeMDV70HR8u2JvHTtiPcf0En\nmjbyq9xJTmZZo9+26A19b6zeAJVSqoa4dKwqY8xirLYKx3VPOSx/wZ93SDnuk4N1Z1VJ59yNdcdW\njcnJK+CZb+Po2DSASYMjKn+iVa9A5iEYPwc8PKstPqWUqkk6yKETZqzczb7UbD65dSDelW0QPxoP\na96C3tdC6xrNe0opVa3cfVdVrbc/NZu3l8dzyVktGNIxrHInMQa+ewy8/OCCqdUan1JK1TRNHOWY\n/r+teIjwj0u6Vf4kO76D+B9h+GPWVK9KKVWHaeIow8odyXy35TBTzutIq6BKzpGRl2OVNsK6wMDb\nqzdApZRyA23jKMOby3YSEerPree0q/xJ1vwbjiXAjd+Ap3e1xaaUUu6iiaMM790YxaH0HHy9KnkH\nVNp+WPUqdB8L7YdXa2xKKeUumjjKENzQh+CGVRi1fenT1s8Lp5e9n1JK1SHaxuEqh2OtXuKD7oKg\nKswOqJRStYwmDldZ8Tz4NobB97g7EqWUqlaaOFzhwAbYtggGT4EGwe6ORimlqpW2cbjC8v+zEsbA\nO9wdiVJ/kZeXR2JiIjk5Oe4ORdUSfn5+hIeH4+3t3J2fmjiq2751Vme/C54Bv0bl769UDUtMTCQw\nMJCIiAhEJxGr94wxpKSkkJiYSLt2znU90Kqq6rb8OWjYFAb8zd2RKFWinJwcQkNDNWkoAESE0NDQ\nCpVANXFUp90/w56VcM6D4NPQ3dEoVSpNGspRRT8PmjiqizGwfDoEtoR+N7k7GqWUchlNHNUlfhns\nXwfnPgTelZzoSal6ICUlhcjISCIjI2nevDmtWrU69Tw3N7fMY2NiYrj33nvLfY3BgwdXV7iqBNo4\nXh2Msdo2gtpAnxvcHY1StVpoaCgbN24EYOrUqQQEBPDQQw+d2p6fn4+XV8lfTVFRUURFRZX7GmvW\nrKmWWGuDsq6Hu9SuaOqq7Yvh4O8w9m3wqsIQJUrVsGe+3ULcwYxqPWf3lo14+rIeFTpm8uTJ+Pn5\n8fvvvzNkyBCuueYa7rvvPnJycmjQoAGzZs2iS5curFixgldeeYVFixYxdepU9u3bx+7du9m3bx/3\n33//qdJIQEAAWVlZrFixgqlTpxIWFkZsbCz9+vXj448/RkRYvHgxDz74IA0bNmTIkCHs3r2bRYsW\nnRZXQkICN9xwA8ePHwfgrbfeOlWaefHFF/n444/x8PBg9OjRvPDCC8THx3PHHXeQnJyMp6cnn3/+\nOfv37z8VM8CUKVOIiopi8uTJTJs2jW+//ZYTJ04wePBg/vvf/yIiDB8+nMjISH755RcmTpzIueee\ny3333cfx48fx9fVl2bJlXHLJJbz55ptERkYCMHToUN5++2169+5dlV+fUzRxVFVhIfw0HUI6QK9r\n3B2NUnVWYmIia9aswdPTk4yMDFatWoWXlxdLly7lH//4B19++eVfjtm2bRvLly8nMzOTLl26cOed\nd/6lL8Lvv//Oli1baNmyJUOGDGH16tVERUVx++23s3LlStq1a8fEiRNLjKlp06b8+OOP+Pn5sXPn\nTiZOnEhMTAxLlizhm2++Yd26dfj7+5OamgrAddddx2OPPcYVV1xBTk4OhYWF7N+/v9T3PGXKFJ56\nyppN+4YbbmDRokVcdtllAOTm5hITE0Nubi5du3Zl3rx59O/fn4yMDBo0aMAtt9zChx9+yOuvv86O\nHTvIycmpkaQBmjiqLm4BHNkCV74Pnno5Vd1S0ZKBK1199dV4elojUaenpzNp0iR27tyJiJCXl1fi\nMZdccgm+vr74+vrStGlTkpKSCA8PP22fAQMGnFoXGRlJQkICAQEBtG/f/lS/hYkTJzJjxoy/nD8v\nL48pU6awceNGPD092bFjBwBLly7lpptuwt/fH4CQkBAyMzM5cOAAV1xxBWB1qivP8uXLeemll8jO\nziY1NZUePXqcShwTJkwAYPv27bRo0YL+/fsD0KhRo1PX69lnn+Xll19m5syZTJ48udzXqy76TVcV\nhQXWmFRNukHPK90djVJ1WsOGf97C/s9//pMRI0bw9ddfk5CQwPDhw0s8xtfX99Syp6cn+fn5ldqn\nNK+99hrNmjVj06ZNFBYWOpUMivPy8qKwsPDU86L+Ejk5Odx1113ExMTQunVrpk6delpfCsfrURJ/\nf39GjhzJN998w/z581m/fn2FY6ssvauqKv74HI7ugBH/AI9KztmhlPqL9PR0WrVqBcCHH35Y7efv\n0qULu3fvJiEhAYB58+aVGkeLFi3w8PDgo48+oqCgAICRI0cya9YssrOzAUhNTSUwMJDw8HAWLFgA\nwMmTJ8nOzqZt27bExcVx8uRJ0tLSWLZsGfBnAgkLCyMrK4svvvii1FgPHTpEdHQ0AJmZmaeS3623\n3sq9995L//79CQ6uuXHxNHFUVkGeVdpo3gu6XebuaJQ6ozzyyCM8/vjj9OnTp0IlBGc1aNCAd955\nh1GjRtGvXz8CAwNp3LjxX/a76667mD17Nr1792bbtm2nSgGjRo1izJgxREVFERkZySuvvALARx99\nxJtvvkmvXr0YPHgwhw8fpnXr1owfP56ePXsyfvx4+vTpA0BQUBB/+9vf6NmzJxdddNGpqqjifHx8\nmDdvHvfccw+9e/dm5MiRp5JOv379aNSoETfdVLN9x8QYU6Mv6A5RUVEmJiamek+6fjZ8ey9cOx86\nX1S951bKhbZu3Uq3bt3cHYbbZWVlERAQgDGGu+++m06dOvHAAw+4O6wKOXjwIMOHD2fbtm14eFSt\nHFDS50JE1htj/nL/s5Y4KiP/JPz8ErSKgk4XujsapVQlvPfee0RGRtKjRw/S09O5/fbb3R1ShcyZ\nM4eBAwcyffr0KieNitISR2WsmwFLHoYbFkCHEdV3XqVqgJY4VEm0xOFKudmw6hVoOwTaD3d3NEop\nVeP0dtyKivkAspJg3CzQEUaVUvWQljgq4mQW/PIadDgPIoa4OxqllHILTRwVse4/kJ0CI550dyRK\nKeU2mjicdSIN1rwJnUdDeD93R6NUnTVixAi+//7709a9/vrr3HnnnaUeM3z4cIpucLn44otJS0v7\nyz5Tp0491Z+iNAsWLCAuLu7U86eeeoqlS5dWIHoFmjic9+s7kJNu9RJXSlXaxIkTmTt37mnr5s6d\nW+pAg8UtXryYoKCgSr128cQxbdo0Lrjggkqdq7ZxRUfJ0mjjuDOyU2HtO9B9LLTo5e5olKo+Sx6D\nw39U7zmbnwWjXyh187hx43jyySfJzc3Fx8eHhIQEDh48yDnnnMOdd95JdHQ0J06cYNy4cTzzzDN/\nOT4iIoKYmBjCwsKYPn06s2fPpmnTprRu3Zp+/azagPfee48ZM2aQm5tLx44d+eijj9i4cSMLFy7k\n559/5rnnnuPLL7/k2Wef5dJLL2XcuHEsW7aMhx56iPz8fPr378+7776Lr68vERERTJo0iW+//Za8\nvDw+//xzunbtelpM9W34dS1xOGP1G5CbBcMfd3ckStV5ISEhDBgwgCVLlgBWaWP8+PGICNOnTycm\nJobNmzfz888/s3nz5lLPs379eubOncvGjRtZvHjxqbGcAK688kqio6PZtGkT3bp144MPPmDw4MGM\nGTOGl19+mY0bN9KhQ4dT++fk5DB58mTmzZvHH3/8QX5+Pu++++6p7WFhYWzYsIE777yzxOqwouHX\nN2zYwLx5807NC+I4/PqmTZt45JFHAGv49bvvvptNmzaxZs0aWrRoUeY1mzJlCtHR0cTGxnLixInT\n5g0pGn79nnvuYcKECbzxxhts2rSJpUuXnjb8OlBtw69riaM8WUfgtxlw1tXQVDtNqTNMGSUDVyqq\nrho7dixz587lgw8+AGD+/PnMmDGD/Px8Dh06RFxcHL16lVzKX7VqFVdcccWpoc3HjBlzaltsbCxP\nPvkkaWlpZGVlcdFFZQ8LtH37dtq1a0fnzp0BmDRpEm+//Tb3338/YCUisMaG+uqrr/5yfH0bfl0T\nR3l+ec0aYmT4Y+6ORKkzxtixY3nggQfYsGED2dnZ9OvXjz179vDKK68QHR1NcHAwkydPPm2Y8YqY\nPHkyCxYsoHfv3nz44YesWLGiSvEWDc1e2rDs9W34da2qKkv6AYj+ACInQmiH8vdXSjklICCAESNG\ncPPNN59qFM/IyKBhw4Y0btyYpKSkU1VZpTn33HNZsGABJ06cIDMzk2+//fbUtszMTFq0aEFeXh6f\nfPLJqfWBgYFkZmb+5VxdunQhISGB+Ph4wBrldtiwYU6/n/o2/LomjrKsehVMIZz7iLsjUeqMM3Hi\nRDZt2nQqcfTu3Zs+ffrQtWtXrr32WoYMKbuTbd++fZkwYQK9e/dm9OjRpw1L/uyzzzJw4ECGDBly\nWkP2Nddcw8svv0yfPn3YtWvXqfV+fn7MmjWLq6++mrPOOgsPDw/uuOMOp99LfRt+3aWDHIrIKOAN\nwBN43xjzQrHtbYGZQBMgFbjeGJNob3sJuAQruf0I3GeMMSIyAXjCPuciY8yj5cVR6UEOV78BJ47B\nBVMrfqxStZQOclj/ODP8eq0Y5FBEPIG3gdFAd2CiiHQvttsrwBxjTC9gGvC8fexgYAjQC+gJ9AeG\niUgo8DJwvjGmB9BcRM531XtgyH2aNJRSdZorhl93ZVXVACDeGLPbGJMLzAXGFtunO/CTvbzcYbsB\n/AAfwBfwBpKA9sBOY0yyvd9S4CqXvQOllKrjbrzxRvbv38/VV19dbed0ZeJoBex3eJ5or3O0CbjS\nXr4CCBSRUGPMWqxEcsh+fG+M2QrEA11EJEJEvIDLgdYlvbiI3CYiMSISk5ycXNIuStVb9WEeHuW8\nin4e3N04/hBWFdTvwDDgAFAgIh2BbkA4VrI5T0TOMcYcA+4E5gGrgASgoKQTG2NmGGOijDFRTZo0\ncf07UaqO8PPzIyUlRZOHAqykkZKSUqFbiF3Zj+MAp5cGwu11pxhjDmKXOEQkALjKGJMmIn8DfjXG\nZNnblgCDgFXGmG+Bb+31t1FK4lBKlSw8PJzExES0JK6K+Pn5ER4e7vT+rkwc0UAnEWmHlTCuAa51\n3EFEwoBUY0wh8DjWHVYA+4C/icjzgGCVRl63j2lqjDkiIsHAXcB4F74Hpc443t7etGvXzt1hqDrM\nZVVVxph8YArwPbAVmG+M2SIi00SkaGyA4cB2EdkBNAOm2+u/AHYBf2C1g2yySxoAb4hIHLAaeMEY\ns8NV70EppdRfubQfR21R6X4cSilVj9V4Pw6llFJnpnpR4hCRZGBvJQ8PA45WYzjVTeOrGo2vajS+\nqqnt8bU1xvzlttR6kTiqQkRiSiqq1RYaX9VofFWj8VVNbY+vNFpVpZRSqkI0cSillKoQTRzlm+Hu\nAMqh8VWNxlc1Gl/V1Pb4SqRtHEoppSpESxxKKaUqRBOHUkqpCtHEYRORUSKyXUTiReSxErb7isg8\ne/s6EYmowdhai8hyEYkTkS0icl8J+wwXkXQR2Wg/nqqp+OzXTxCRP+zX/ks3fbG8aV+/zSLStwZj\n6+JwXTaKSIaI3F9snxq9fiIyU0SOiEisw7oQEflRRHbaP0ucHFpEJtn77BSRSTUY38siss3+/X0t\nIkGlHFvmZ8GF8U0VkQMOv8OLSzm2zL91F8Y3zyG2BBHZWMqxLr9+VWaMqfcPrGlod2FNFOWDNT5W\n92L73AX8x16+BphXg/G1APray4HAjhLiG441la67rmECEFbG9ouBJViDVp4NrHPj7/owVscmt10/\n4FygLxDrsO4l4DF7+THgxRKOCwF22z+D7eXgGorvQsDLXn6xpPic+Sy4ML6pwENO/P7L/Ft3VXzF\ntr8KPOWu61fVh5Y4LM7MVjgWmG0vfwGcLyJSE8EZYw4ZYzbYy5lYg0YWnxSrthuLNU2wMcb8CgSJ\nSAs3xHE+sMsYU9mRBKqFMWYlkFpsteNnbDbWRGXFXQT8aIxJNdb8ND8Co2oiPmPMD8YavBTgV6yp\nEtyilOvnDGf+1qusrPjs743xwGfV/bo1RROHxZnZCk/tY//xpAOhNRKdA7uKrA+wroTNg0Rkk4gs\nEZEeNRsZBvhBRNbb86QU58w1rgnXUPofrDuvH0AzY8whe/kw1ojRxdWW63gzVgmyJOV9Flxpil2V\nNrOUqr7acP3OAZKMMTtL2e7O6+cUTRx1iFiTXX0J3G+MySi2eQNW9Utv4N/AghoOb6gxpi8wGrhb\nRM6t4dcvl4j4AGOAz0vY7O7rdxpj1VnUynvlReQJIB/4pJRd3PVZeBfoAERiTTn9ag29bkVNpOzS\nRq3/W9LEYSl3tkLHfcSa77wxkFIj0Vmv6Y2VND4xxnxVfLsxJsPYMyYaYxYD3mJNlFUjjDEH7J9H\ngK+xqgQcOXONXW00sMEYk1R8g7uvny2pqPrO/nmkhH3ceh1FZDJwKXCdndz+wonPgksYY5KMMQXG\nmhjuvVJe193Xzwtr1tN5pe3jrutXEZo4LKdmK7T/K70GWFhsn4VA0R0s44CfSvvDqW52negHwFZj\nzL9K2ad5UZuLiAzA+t3WSGITkYYiEli0jNWIGltst4XAjfbdVWcD6Q7VMjWl1P/03Hn9HDh+xiYB\n35Swz/fAhSISbFfFXGivczkRGQU8AowxxmSXso8znwVXxefYZnZFKa/rzN+6K10AbDPGJJa00Z3X\nr0Lc3TpfWx5Yd/3swLrj4gl73TSsPxIAP6wqjnjgN6B9DcY2FKvaYjOw0X5cDNwB3GHvMwXYgnWX\nyK/A4BqMr739upvsGIqun2N8ArzNnzM7RtXw77chViJo7LDObdcPK4EdAvKw6tlvwWozWwbsBJYC\nIfa+UcD7DsfebH8O44GbajC+eKz2gaLPYNFdhi2BxWV9Fmoovo/sz9ZmrGTQonh89vO//K3XRHz2\n+g+LPnMO+9b49avqQ4ccUUopVSFaVaWUUqpCNHEopZSqEE0cSimlKkQTh1JKqQrRxKGUUqpCNHEo\nVUkiUiCnj7pbbSOtikiE48iqStUmXu4OQKk67IQxJtLdQShV07TEoVQ1s+dTeMmeU+E3Eelor48Q\nkZ/sQfiWiUgbe30ze36LTfZjsH0qTxF5T6w5WH4QkQb2/veKNTfLZhGZ66a3qeoxTRxKVV6DYlVV\nExy2pRtjzgLeAl631/0bmG2M6YU1QOCb9vo3gZ+NNcBiX6wewwCdgLeNMT2ANOAqe/1jQB/7PHe4\n5q0pVTrtOa5UJYlIljEmoIT1CcB5xpjd9uCUh40xoSJyFGsYjDx7/SFjTJiIJAPhxpiTDueIwJp3\no5P9/FHA2xjznIh8B2RhjeC7wNiDMypVU7TEoZRrmFKWK+Kkw3IBf7ZJXoI17ldfINoecVWpGqOJ\nQynXmODwc629vAZrNFaA64BV9vIy4E4AEfEUkcalnVREPIDWxpjlwKNYw/v/pdSjlCvpfypKVV4D\nEdno8Pw7Y0zRLbnBIrIZq9Qw0V53DzBLRB4GkoGb7PX3ATNE5BasksWdWCOrlsQT+NhOLgK8aYxJ\nq6b3o5RTtI1DqWpmt3FEGWOOujsWpVxBq6qUUkpViJY4lFJKVYiWOJRSSlWIJg6llFIVoolDKaVU\nhWjiUEopVSGaOJRSSlXI/wOtd7lZFQzjZgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_history(network_history):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(network_history.history['loss'], label='Training loss')\n",
    "    plt.plot(network_history.history['val_loss'], label='Validation loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and validation loss')\n",
    "    \n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(network_history.history['acc'], label='Training accuarcy')\n",
    "    plt.plot(network_history.history['val_acc'], label='Validation accuarcy')\n",
    "    plt.legend( loc='lower right')\n",
    "    plt.title('Training and validation accuarcy')\n",
    "    plt.show()\n",
    "\n",
    "plot_history(att2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 300)          105666600 \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 128)          219648    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 128)          0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100, 64)           8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100, 64)           0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100, 5)            325       \n",
      "=================================================================\n",
      "Total params: 105,894,829\n",
      "Trainable params: 228,229\n",
      "Non-trainable params: 105,666,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jojo\\anaconda3\\envs\\your_env_name\\lib\\site-packages\\pyecharts\\charts\\chart.py:14: PendingDeprecationWarning: pyecharts 所有图表类型将在 v1.9.0 版本开始强制使用 ChartItem 进行数据项配置 :)\n",
      "  super().__init__(init_opts=init_opts)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<script>\n",
       "    require.config({\n",
       "        paths: {\n",
       "            'echarts':'https://assets.pyecharts.org/assets/echarts.min'\n",
       "        }\n",
       "    });\n",
       "</script>\n",
       "\n",
       "        <div id=\"d1b935f58a0b48ffb63c17d6a628dc0c\" style=\"width:900px; height:500px;\"></div>\n",
       "\n",
       "<script>\n",
       "        require(['echarts'], function(echarts) {\n",
       "                var chart_d1b935f58a0b48ffb63c17d6a628dc0c = echarts.init(\n",
       "                    document.getElementById('d1b935f58a0b48ffb63c17d6a628dc0c'), 'white', {renderer: 'canvas'});\n",
       "                var option_d1b935f58a0b48ffb63c17d6a628dc0c = {\n",
       "    \"animation\": true,\n",
       "    \"animationThreshold\": 2000,\n",
       "    \"animationDuration\": 1000,\n",
       "    \"animationEasing\": \"cubicOut\",\n",
       "    \"animationDelay\": 0,\n",
       "    \"animationDurationUpdate\": 300,\n",
       "    \"animationEasingUpdate\": \"cubicOut\",\n",
       "    \"animationDelayUpdate\": 0,\n",
       "    \"color\": [\n",
       "        \"#c23531\",\n",
       "        \"#2f4554\",\n",
       "        \"#61a0a8\",\n",
       "        \"#d48265\",\n",
       "        \"#749f83\",\n",
       "        \"#ca8622\",\n",
       "        \"#bda29a\",\n",
       "        \"#6e7074\",\n",
       "        \"#546570\",\n",
       "        \"#c4ccd3\",\n",
       "        \"#f05b72\",\n",
       "        \"#ef5b9c\",\n",
       "        \"#f47920\",\n",
       "        \"#905a3d\",\n",
       "        \"#fab27b\",\n",
       "        \"#2a5caa\",\n",
       "        \"#444693\",\n",
       "        \"#726930\",\n",
       "        \"#b2d235\",\n",
       "        \"#6d8346\",\n",
       "        \"#ac6767\",\n",
       "        \"#1d953f\",\n",
       "        \"#6950a1\",\n",
       "        \"#918597\"\n",
       "    ],\n",
       "    \"series\": [\n",
       "        {\n",
       "            \"type\": \"line\",\n",
       "            \"name\": \"loss\",\n",
       "            \"connectNulls\": false,\n",
       "            \"symbolSize\": 4,\n",
       "            \"showSymbol\": true,\n",
       "            \"smooth\": true,\n",
       "            \"clip\": true,\n",
       "            \"step\": false,\n",
       "            \"data\": [\n",
       "                [\n",
       "                    1,\n",
       "                    0.4802301026871197\n",
       "                ],\n",
       "                [\n",
       "                    2,\n",
       "                    0.2168506471216991\n",
       "                ],\n",
       "                [\n",
       "                    3,\n",
       "                    0.18527901265130298\n",
       "                ],\n",
       "                [\n",
       "                    4,\n",
       "                    0.16873371752077257\n",
       "                ],\n",
       "                [\n",
       "                    5,\n",
       "                    0.1563237729628011\n",
       "                ],\n",
       "                [\n",
       "                    6,\n",
       "                    0.14899198544675124\n",
       "                ],\n",
       "                [\n",
       "                    7,\n",
       "                    0.14216178118891054\n",
       "                ],\n",
       "                [\n",
       "                    8,\n",
       "                    0.13660024561676\n",
       "                ],\n",
       "                [\n",
       "                    9,\n",
       "                    0.13381953005936756\n",
       "                ],\n",
       "                [\n",
       "                    10,\n",
       "                    0.12927497416227984\n",
       "                ],\n",
       "                [\n",
       "                    11,\n",
       "                    0.12643126351471426\n",
       "                ],\n",
       "                [\n",
       "                    12,\n",
       "                    0.12343909710912915\n",
       "                ],\n",
       "                [\n",
       "                    13,\n",
       "                    0.12300090985989784\n",
       "                ],\n",
       "                [\n",
       "                    14,\n",
       "                    0.12023347463921671\n",
       "                ],\n",
       "                [\n",
       "                    15,\n",
       "                    0.1178462789637448\n",
       "                ],\n",
       "                [\n",
       "                    16,\n",
       "                    0.1188771209338012\n",
       "                ],\n",
       "                [\n",
       "                    17,\n",
       "                    0.11570454915004795\n",
       "                ],\n",
       "                [\n",
       "                    18,\n",
       "                    0.11531909506000544\n",
       "                ],\n",
       "                [\n",
       "                    19,\n",
       "                    0.1150513972704869\n",
       "                ],\n",
       "                [\n",
       "                    20,\n",
       "                    0.11327404693364264\n",
       "                ]\n",
       "            ],\n",
       "            \"hoverAnimation\": true,\n",
       "            \"label\": {\n",
       "                \"show\": true,\n",
       "                \"position\": \"top\",\n",
       "                \"margin\": 8\n",
       "            },\n",
       "            \"lineStyle\": {\n",
       "                \"show\": true,\n",
       "                \"width\": 1,\n",
       "                \"opacity\": 1,\n",
       "                \"curveness\": 0,\n",
       "                \"type\": \"solid\"\n",
       "            },\n",
       "            \"areaStyle\": {\n",
       "                \"opacity\": 0.5\n",
       "            },\n",
       "            \"markPoint\": {\n",
       "                \"label\": {\n",
       "                    \"show\": true,\n",
       "                    \"position\": \"inside\",\n",
       "                    \"color\": \"#fff\",\n",
       "                    \"margin\": 8\n",
       "                },\n",
       "                \"data\": [\n",
       "                    {\n",
       "                        \"type\": \"max\"\n",
       "                    },\n",
       "                    {\n",
       "                        \"type\": \"min\"\n",
       "                    }\n",
       "                ]\n",
       "            },\n",
       "            \"zlevel\": 0,\n",
       "            \"z\": 0\n",
       "        },\n",
       "        {\n",
       "            \"type\": \"line\",\n",
       "            \"name\": \"accuarcy\",\n",
       "            \"connectNulls\": false,\n",
       "            \"symbolSize\": 4,\n",
       "            \"showSymbol\": false,\n",
       "            \"smooth\": true,\n",
       "            \"clip\": true,\n",
       "            \"step\": false,\n",
       "            \"data\": [\n",
       "                [\n",
       "                    1,\n",
       "                    0.8653662506340407\n",
       "                ],\n",
       "                [\n",
       "                    2,\n",
       "                    0.9306777684794353\n",
       "                ],\n",
       "                [\n",
       "                    3,\n",
       "                    0.9413601963500892\n",
       "                ],\n",
       "                [\n",
       "                    4,\n",
       "                    0.9464679178389734\n",
       "                ],\n",
       "                [\n",
       "                    5,\n",
       "                    0.9507290093449257\n",
       "                ],\n",
       "                [\n",
       "                    6,\n",
       "                    0.9527448479824104\n",
       "                ],\n",
       "                [\n",
       "                    7,\n",
       "                    0.9550902542016192\n",
       "                ],\n",
       "                [\n",
       "                    8,\n",
       "                    0.9569011287152233\n",
       "                ],\n",
       "                [\n",
       "                    9,\n",
       "                    0.9577570752643854\n",
       "                ],\n",
       "                [\n",
       "                    10,\n",
       "                    0.9591254210727546\n",
       "                ],\n",
       "                [\n",
       "                    11,\n",
       "                    0.9602701773990001\n",
       "                ],\n",
       "                [\n",
       "                    12,\n",
       "                    0.9612647048930315\n",
       "                ],\n",
       "                [\n",
       "                    13,\n",
       "                    0.9613206021802673\n",
       "                ],\n",
       "                [\n",
       "                    14,\n",
       "                    0.9625969497638572\n",
       "                ],\n",
       "                [\n",
       "                    15,\n",
       "                    0.9629684392004056\n",
       "                ],\n",
       "                [\n",
       "                    16,\n",
       "                    0.9627634789358686\n",
       "                ],\n",
       "                [\n",
       "                    17,\n",
       "                    0.9636194230139401\n",
       "                ],\n",
       "                [\n",
       "                    18,\n",
       "                    0.9640875742615095\n",
       "                ],\n",
       "                [\n",
       "                    19,\n",
       "                    0.9641260061245158\n",
       "                ],\n",
       "                [\n",
       "                    20,\n",
       "                    0.9647082780200749\n",
       "                ]\n",
       "            ],\n",
       "            \"hoverAnimation\": true,\n",
       "            \"label\": {\n",
       "                \"show\": true,\n",
       "                \"position\": \"top\",\n",
       "                \"margin\": 8\n",
       "            },\n",
       "            \"lineStyle\": {\n",
       "                \"show\": true,\n",
       "                \"width\": 1,\n",
       "                \"opacity\": 1,\n",
       "                \"curveness\": 0,\n",
       "                \"type\": \"solid\"\n",
       "            },\n",
       "            \"areaStyle\": {\n",
       "                \"opacity\": 0.5\n",
       "            },\n",
       "            \"markPoint\": {\n",
       "                \"label\": {\n",
       "                    \"show\": true,\n",
       "                    \"position\": \"inside\",\n",
       "                    \"color\": \"#fff\",\n",
       "                    \"margin\": 8\n",
       "                },\n",
       "                \"data\": [\n",
       "                    {\n",
       "                        \"type\": \"min\"\n",
       "                    },\n",
       "                    {\n",
       "                        \"type\": \"max\"\n",
       "                    }\n",
       "                ]\n",
       "            },\n",
       "            \"zlevel\": 0,\n",
       "            \"z\": 0\n",
       "        }\n",
       "    ],\n",
       "    \"legend\": [\n",
       "        {\n",
       "            \"data\": [\n",
       "                \"loss\",\n",
       "                \"accuarcy\"\n",
       "            ],\n",
       "            \"selected\": {\n",
       "                \"loss\": true,\n",
       "                \"accuarcy\": true\n",
       "            },\n",
       "            \"show\": true,\n",
       "            \"padding\": 5,\n",
       "            \"itemGap\": 10,\n",
       "            \"itemWidth\": 25,\n",
       "            \"itemHeight\": 14\n",
       "        }\n",
       "    ],\n",
       "    \"tooltip\": {\n",
       "        \"show\": true,\n",
       "        \"trigger\": \"item\",\n",
       "        \"triggerOn\": \"mousemove|click\",\n",
       "        \"axisPointer\": {\n",
       "            \"type\": \"line\"\n",
       "        },\n",
       "        \"showContent\": true,\n",
       "        \"alwaysShowContent\": false,\n",
       "        \"showDelay\": 0,\n",
       "        \"hideDelay\": 100,\n",
       "        \"textStyle\": {\n",
       "            \"fontSize\": 14\n",
       "        },\n",
       "        \"borderWidth\": 0,\n",
       "        \"padding\": 5\n",
       "    },\n",
       "    \"xAxis\": [\n",
       "        {\n",
       "            \"show\": true,\n",
       "            \"scale\": false,\n",
       "            \"nameLocation\": \"end\",\n",
       "            \"nameGap\": 15,\n",
       "            \"gridIndex\": 0,\n",
       "            \"inverse\": false,\n",
       "            \"offset\": 0,\n",
       "            \"splitNumber\": 5,\n",
       "            \"minInterval\": 0,\n",
       "            \"splitLine\": {\n",
       "                \"show\": false,\n",
       "                \"lineStyle\": {\n",
       "                    \"show\": true,\n",
       "                    \"width\": 1,\n",
       "                    \"opacity\": 1,\n",
       "                    \"curveness\": 0,\n",
       "                    \"type\": \"solid\"\n",
       "                }\n",
       "            },\n",
       "            \"data\": [\n",
       "                1,\n",
       "                2,\n",
       "                3,\n",
       "                4,\n",
       "                5,\n",
       "                6,\n",
       "                7,\n",
       "                8,\n",
       "                9,\n",
       "                10,\n",
       "                11,\n",
       "                12,\n",
       "                13,\n",
       "                14,\n",
       "                15,\n",
       "                16,\n",
       "                17,\n",
       "                18,\n",
       "                19,\n",
       "                20\n",
       "            ]\n",
       "        }\n",
       "    ],\n",
       "    \"yAxis\": [\n",
       "        {\n",
       "            \"show\": true,\n",
       "            \"scale\": false,\n",
       "            \"nameLocation\": \"end\",\n",
       "            \"nameGap\": 15,\n",
       "            \"gridIndex\": 0,\n",
       "            \"inverse\": false,\n",
       "            \"offset\": 0,\n",
       "            \"splitNumber\": 5,\n",
       "            \"minInterval\": 0,\n",
       "            \"splitLine\": {\n",
       "                \"show\": false,\n",
       "                \"lineStyle\": {\n",
       "                    \"show\": true,\n",
       "                    \"width\": 1,\n",
       "                    \"opacity\": 1,\n",
       "                    \"curveness\": 0,\n",
       "                    \"type\": \"solid\"\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    ],\n",
       "    \"title\": [\n",
       "        {\n",
       "            \"text\": \"BiGRU_history\",\n",
       "            \"padding\": 5,\n",
       "            \"itemGap\": 10\n",
       "        }\n",
       "    ]\n",
       "};\n",
       "                chart_d1b935f58a0b48ffb63c17d6a628dc0c.setOption(option_d1b935f58a0b48ffb63c17d6a628dc0c);\n",
       "        });\n",
       "    </script>\n"
      ],
      "text/plain": [
       "<pyecharts.render.display.HTML at 0x205ad1234e0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyecharts.options as opts\n",
    "from pyecharts.charts import Line\n",
    "c = (        \n",
    "    Line()       \n",
    "    .add_xaxis([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])     \n",
    "    .add_yaxis(\"loss\",BiGRU_history.history['loss'], is_smooth=True, areastyle_opts=opts.AreaStyleOpts(opacity=0.5),\n",
    "              markpoint_opts=opts.MarkPointOpts(data=[opts.MarkPointItem(type_=\"max\"),opts.MarkPointItem(type_=\"min\")]),  #点出来\n",
    "         )       \n",
    "    .add_yaxis(\"accuarcy\",BiGRU_history.history['acc'], is_smooth=True, areastyle_opts=opts.AreaStyleOpts(opacity=0.5),is_symbol_show=False,\n",
    "              markpoint_opts=opts.MarkPointOpts(data=[opts.MarkPointItem(type_=\"min\"),opts.MarkPointItem(type_=\"max\")]),  #点出来\n",
    "         )        \n",
    "    .set_global_opts(title_opts=opts.TitleOpts(title=\"BiGRU_history\"))    \n",
    ")\n",
    "\n",
    "c.render_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6、测试与检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[7.86209057e-07 9.76780370e-07 1.20981771e-03 ... 5.69924386e-03\n",
      "   4.14206646e-02 5.38108907e-07]\n",
      "  [1.13918541e-10 1.90582355e-10 1.49025675e-06 ... 8.56595725e-05\n",
      "   3.54829081e-03 4.55332327e-10]\n",
      "  [8.23291695e-12 4.37434845e-11 2.12401541e-09 ... 4.21064626e-03\n",
      "   4.37797826e-06 2.11769887e-07]\n",
      "  ...\n",
      "  [1.29847663e-07 1.77626006e-07 1.10353678e-04 ... 1.59663300e-03\n",
      "   2.33148858e-02 4.22922966e-07]\n",
      "  [1.29847663e-07 1.77626006e-07 1.10353678e-04 ... 1.59663300e-03\n",
      "   2.33148858e-02 4.22922966e-07]\n",
      "  [1.29847422e-07 1.77626006e-07 1.10353576e-04 ... 1.59663218e-03\n",
      "   2.33148746e-02 4.22922170e-07]]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X_test_tokenized[:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test_index_padded[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.13102112e-16 2.08415832e-16 4.50650139e-09 ... 6.19673017e-07\n",
      "   9.95569394e-07 1.02205071e-14]\n",
      "  [2.19632980e-07 6.09879294e-07 1.05608546e-03 ... 7.32004584e-04\n",
      "   6.74455389e-02 2.43706268e-07]\n",
      "  [3.03420102e-11 7.46342640e-11 1.24274777e-06 ... 3.36084922e-05\n",
      "   5.20084985e-03 1.16109553e-10]\n",
      "  ...\n",
      "  [1.29847791e-07 1.77626006e-07 1.10353678e-04 ... 1.59663300e-03\n",
      "   2.33148858e-02 4.22922966e-07]\n",
      "  [1.29847663e-07 1.77626006e-07 1.10353678e-04 ... 1.59663300e-03\n",
      "   2.33148858e-02 4.22922966e-07]\n",
      "  [1.29847663e-07 1.77626006e-07 1.10353576e-04 ... 1.59663218e-03\n",
      "   2.33148746e-02 4.22922170e-07]]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X_test_tokenized[2:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test_index_padded[2:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7、模型的储存与加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "# 模型的存储\n",
    "pm = \"./cixing_model.h5\"\n",
    "model.save(pm)\n",
    "print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Using loaded model to predict...\n",
      "预测结果为：\n",
      " [4.04630300e-05 1.16919955e-06 7.85740256e-01 1.62828553e-06\n",
      " 5.10407153e-05 7.18984347e-06 3.44756677e-06 1.25117496e-01\n",
      " 2.09058067e-04 6.97166570e-06 9.69335204e-04 7.97817734e-07\n",
      " 3.54493549e-03 1.18479504e-04 1.05112523e-03 2.56112020e-04\n",
      " 8.77654384e-06 1.40340069e-06 2.59451587e-02 1.45456170e-05\n",
      " 8.80271837e-05 5.80040137e-07 8.32478472e-05 1.08266051e-03\n",
      " 7.69139209e-04 1.69123829e-04 7.66462600e-03 1.37587544e-03\n",
      " 2.79088417e-04 3.96143682e-02 2.69746437e-04 2.65271274e-06\n",
      " 3.48273921e-09 1.16690656e-03 6.85484395e-07 9.11407128e-08\n",
      " 4.34363168e-03]\n"
     ]
    }
   ],
   "source": [
    "# 加载存储的模型开始预测\n",
    "from keras.models import load_model\n",
    "\n",
    "print(\"Loading model...\")\n",
    "load_model = load_model(\"./cixing_model.h5\")\n",
    "\n",
    "# 使用测试集中的第一条开始预测\n",
    "print(\"Using loaded model to predict...\")\n",
    "predicted = load_model.predict(X_test_tokenized[:1])\n",
    "\n",
    "# 呈现预测结果\n",
    "print(\"预测结果为：\\n\", predicted[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_test_index_padded[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
