{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取本地模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"model_NB.pickle\", \"rb\")\n",
    "# 把模型从文件中读取出来\n",
    "model = pickle.load(file)\n",
    "# 关闭文件\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"tfidf_vect_ngram.pickle\", \"rb\")\n",
    "# 把模型从文件中读取出来\n",
    "tfidf_vect_ngram = pickle.load(file)\n",
    "# 关闭文件\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"logistic.pickle\", \"rb\")\n",
    "# 把模型从文件中读取出来\n",
    "logistic = pickle.load(file)\n",
    "# 关闭文件\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用本地模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#暴力拆字\n",
    "def zi(test):\n",
    "    data=[]\n",
    "    for item in test:\n",
    "        #print(item)\n",
    "        item=\" \".join(item)\n",
    "        #print(item)\n",
    "        data=[item]\n",
    "        #print(data)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuhao(test):\n",
    "    test_data_pro=[]\n",
    "    for paragraph in test:\n",
    "        test_data_pro.append(' '.join(list((re.sub(\"[\\s+\\.\\!\\/_,$%^*)(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）“”]\", \"\",paragraph)))))\n",
    "    return test_data_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def se(test):\n",
    "    train_data_prop = []\n",
    "    for paragraph in test:\n",
    "        train_data_prop.append(\"<start> \"+paragraph+\" <end>\")\n",
    "    return train_data_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[\"梁国杨氏子九岁，甚聪惠。孔君平诣其父，父不在，乃呼儿出。为设果，果有杨梅。孔指以示儿曰：\"+\n",
    "      \"“此是君家果。”儿应声答曰：“未闻孔雀是夫子家禽。”\"]\n",
    "test_result=\"classical\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start> 梁 国 杨 氏 子 九 岁 甚 聪 惠 孔 君 平 诣 其 父 父 不 在 乃 呼 儿 出 为 设 果 果 有 杨 梅 孔 指 以 示 儿 曰 ： 此 是 君 家 果 儿 应 声 答 曰 ： 未 闻 孔 雀 是 夫 子 家 禽 <end>']\n"
     ]
    }
   ],
   "source": [
    "test=zi(test)\n",
    "test=fuhao(test)\n",
    "test=se(test)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_NB+CV预测值： ['modern']\n",
      "model_NB+TFIDF预测值： ['poet']\n",
      "线性回归+TFIDF预测值： ['classical']\n",
      "线性回归+CV预测值： ['poet']\n",
      "实际值： classical\n"
     ]
    }
   ],
   "source": [
    "print(\"model_NB+CV预测值：\", model_NB.predict(vectorizer.transform(test)))\n",
    "print(\"model_NB+TFIDF预测值：\", model_NB.predict(tfidf_vect_ngram.transform(test)))\n",
    "print(\"线性回归+TFIDF预测值：\", logistic.predict(tfidf_vect_ngram.transform(test)))\n",
    "print(\"线性回归+CV预测值：\", logistic.predict(vectorizer.transform(test)))\n",
    "print(\"实际值：\",test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_poet=[\"床前明月光，疑是地上霜。举头望明月，低头思故乡。\"]\n",
    "test_poet_result=\"poet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start> 床 前 明 月 光 疑 是 地 上 霜 举 头 望 明 月 低 头 思 故 乡 <end>']\n"
     ]
    }
   ],
   "source": [
    "test_poet=zi(test_poet)\n",
    "test_poet=fuhao(test_poet)\n",
    "test_poet=se(test_poet)\n",
    "print(test_poet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_NB+CV预测值： ['modern']\n",
      "model_NB+TFIDF预测值： ['poet']\n",
      "线性回归+TFIDF预测值： ['poet']\n",
      "线性回归+CV预测值： ['poet']\n",
      "实际值： poet\n"
     ]
    }
   ],
   "source": [
    "print(\"model_NB+CV预测值：\", model_NB.predict(vectorizer.transform(test_poet)))\n",
    "print(\"model_NB+TFIDF预测值：\", model_NB.predict(tfidf_vect_ngram.transform(test_poet)))\n",
    "print(\"线性回归+TFIDF预测值：\", logistic.predict(tfidf_vect_ngram.transform(test_poet)))\n",
    "print(\"线性回归+CV预测值：\", logistic.predict(vectorizer.transform(test_poet)))\n",
    "print(\"实际值：\",test_poet_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ci=[\"怒发冲冠，凭栏处、潇潇雨歇。抬望眼、仰天长啸，壮怀激烈。三十功名尘与土，八千里路云和月。莫等闲、白了少年头，空悲切。靖康耻，犹未雪。臣子恨，何时灭。驾长车，踏破贺兰山缺。壮志饥餐胡虏肉，笑谈渴饮匈奴血。\"]\n",
    "test_ci_result=\"ci\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start> 怒 发 冲 冠 凭 栏 处 潇 潇 雨 歇 抬 望 眼 仰 天 长 啸 壮 怀 激 烈 三 十 功 名 尘 与 土 八 千 里 路 云 和 月 莫 等 闲 白 了 少 年 头 空 悲 切 靖 康 耻 犹 未 雪 臣 子 恨 何 时 灭 驾 长 车 踏 破 贺 兰 山 缺 壮 志 饥 餐 胡 虏 肉 笑 谈 渴 饮 匈 奴 血 <end>']\n"
     ]
    }
   ],
   "source": [
    "test_ci=zi(test_ci)\n",
    "test_ci=fuhao(test_ci)\n",
    "test_ci=se(test_ci)\n",
    "print(test_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_NB+CV预测值： ['poet']\n",
      "model_NB+TFIDF预测值： ['poet']\n",
      "线性回归+TFIDF预测值： ['ci']\n",
      "线性回归+CV预测值： ['poet']\n",
      "实际值： ci\n"
     ]
    }
   ],
   "source": [
    "print(\"model_NB+CV预测值：\", model_NB.predict(vectorizer.transform(test_ci)))\n",
    "print(\"model_NB+TFIDF预测值：\", model_NB.predict(tfidf_vect_ngram.transform(test_ci)))\n",
    "print(\"线性回归+TFIDF预测值：\", logistic.predict(tfidf_vect_ngram.transform(test_ci)))\n",
    "print(\"线性回归+CV预测值：\", logistic.predict(vectorizer.transform(test_ci)))\n",
    "print(\"实际值：\",test_ci_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_modern=[\"2020年10月20日，全国双拥模范城（县）命名暨双拥模范单位和个人表彰大会举行，习近平总书记亲切会见与会代表，向他们表示诚挚问候，向受到命名表彰的全国双拥模范城（县）、双拥模范单位和个人表示热烈祝贺。\"]\n",
    "test_modern_result=\"modern\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start> 2 0 2 0 年 1 0 月 2 0 日 全 国 双 拥 模 范 城 县 命 名 暨 双 拥 模 范 单 位 和 个 人 表 彰 大 会 举 行 习 近 平 总 书 记 亲 切 会 见 与 会 代 表 向 他 们 表 示 诚 挚 问 候 向 受 到 命 名 表 彰 的 全 国 双 拥 模 范 城 县 双 拥 模 范 单 位 和 个 人 表 示 热 烈 祝 贺 <end>']\n"
     ]
    }
   ],
   "source": [
    "test_modern=zi(test_modern)\n",
    "test_modern=fuhao(test_modern)\n",
    "test_modern=se(test_modern)\n",
    "print(test_modern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_NB+CV预测值： ['modern']\n",
      "model_NB+TFIDF预测值： ['poet']\n",
      "线性回归+TFIDF预测值： ['modern']\n",
      "线性回归+CV预测值： ['poet']\n",
      "实际值： modern\n"
     ]
    }
   ],
   "source": [
    "print(\"model_NB+CV预测值：\", model_NB.predict(vectorizer.transform(test_modern)))\n",
    "print(\"model_NB+TFIDF预测值：\", model_NB.predict(tfidf_vect_ngram.transform(test_modern)))\n",
    "print(\"线性回归+TFIDF预测值：\", logistic.predict(tfidf_vect_ngram.transform(test_modern)))\n",
    "print(\"线性回归+CV预测值：\", logistic.predict(vectorizer.transform(test_modern)))\n",
    "print(\"实际值：\",test_modern_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集预测 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "线性回归+TFIDF准确度为：0.8675\n",
      "线性回归+CV准确度为：0.25\n",
      "model_NB+CV准确度为：0.5175\n",
      "model_NB+TFIDF准确度为：0.265\n"
     ]
    }
   ],
   "source": [
    "poetry_data_try=[]\n",
    "ci_data_try=[]\n",
    "news_data_try=[]\n",
    "train=[]\n",
    "target=[]\n",
    "cursor = c.execute(\"SELECT * from poet order by id desc limit 200\")\n",
    "for row in cursor:\n",
    "    poetry_data_try.append(row)\n",
    "for i in range(0,len(poetry_data_try)):\n",
    "    train.append(poetry_data_try[i][1])\n",
    "    target.append(poetry_data_try[i][2])\n",
    "\n",
    "cursor = c.execute(\"SELECT * from ci order by id desc limit 200\")\n",
    "for row in cursor:\n",
    "    ci_data_try.append(row)\n",
    "for i in range(0,len(ci_data_try)):\n",
    "    train.append(ci_data_try[i][1])\n",
    "    target.append(ci_data_try[i][2])\n",
    "\n",
    "modern_data_try=[]\n",
    "cursor = c.execute(\"SELECT * from news order by id desc limit 200\")\n",
    "for row in cursor:\n",
    "    modern_data_try.append(row)\n",
    "cursor = c.execute(\"SELECT * from journal order by id desc limit 200\")\n",
    "for row in cursor:\n",
    "    modern_data_try.append(row)\n",
    "\n",
    "for i in range(0,len(modern_data_try)):\n",
    "    train.append(modern_data_try[i][1])\n",
    "    target.append(modern_data_try[i][2])\n",
    "\n",
    "data=[]\n",
    "for i in range(0,len(train)):\n",
    "    train[i]=zi([train[i]])\n",
    "    #print(train[i])\n",
    "    train[i]=fuhao(train[i])\n",
    "    #print(train[i])\n",
    "    train[i]=se(train[i])\n",
    "    #print(train[i])\n",
    "#print(train[0])\n",
    "\n",
    "pred=[]\n",
    "for i in range(0,len(train)):\n",
    "    pred.append(logistic.predict(tfidf_vect_ngram.transform(train[i])))\n",
    "count=0\n",
    "for i in range(0,len(target)):\n",
    "    if(pred[i]==target[i]):\n",
    "        count=count+1\n",
    "print(\"线性回归+TFIDF准确度为：\"+str(count/(len(target))))\n",
    "\n",
    "pred=[]\n",
    "for i in range(0,len(train)):\n",
    "    pred.append(logistic.predict(vectorizer.transform(train[i])))\n",
    "count=0\n",
    "for i in range(0,len(target)):\n",
    "    if(pred[i]==target[i]):\n",
    "        count=count+1\n",
    "print(\"线性回归+CV准确度为：\"+str(count/(len(target))))\n",
    "\n",
    "pred=[]\n",
    "for i in range(0,len(train)):\n",
    "    pred.append(classifier.predict(vectorizer.transform(train[i])))\n",
    "\n",
    "count=0\n",
    "for i in range(0,len(target)):\n",
    "    if(pred[i]==target[i]):\n",
    "        count=count+1\n",
    "print(\"model_NB+CV准确度为：\"+str(count/(len(target))))\n",
    "\n",
    "pred=[]\n",
    "for i in range(0,len(train)):\n",
    "    pred.append(model_NB.predict(tfidf_vect_ngram.transform(train[i])))\n",
    "\n",
    "count=0\n",
    "for i in range(0,len(target)):\n",
    "    if(pred[i]==target[i]):\n",
    "        count=count+1\n",
    "print(\"model_NB+TFIDF准确度为：\"+str(count/(len(target))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
